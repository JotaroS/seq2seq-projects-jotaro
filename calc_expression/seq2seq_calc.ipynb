{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.6.3 64-bit ('anaconda3-5.0.1': pyenv)",
      "metadata": {
        "interpreter": {
          "hash": "b32d374ffa8d18e4b45dd340fabb43f42c7307bd4f81ba94e298a0a3f3a465e1"
        }
      }
    },
    "colab": {
      "name": "seq2seq_calc.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "tBUTpSzp4jkK",
        "outputId": "07b0f0bd-43c5-4c3f-9170-d4304569bd5b"
      },
      "source": [
        "!pip install wandb\n",
        "import numpy as np\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, TimeDistributed, RepeatVector, Dense\n",
        "\n",
        "wandb.init()\n",
        "config = wandb.config"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.6/dist-packages (0.10.19)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.8.1)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.1.13)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: sentry-sdk>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: configparser>=3.8.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.0.1)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.0.1)\n",
            "Requirement already satisfied: subprocess32>=3.5.3 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.5.4)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.12.4)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.6/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.6/dist-packages (from GitPython>=1.0.0->wandb) (4.0.5)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from sentry-sdk>=0.4.0->wandb) (2020.12.5)\n",
            "Requirement already satisfied: urllib3>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.12.0->wandb) (53.0.0)\n",
            "Requirement already satisfied: smmap<4,>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (3.0.5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjotaro\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.19<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">firm-sky-10</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/jotaro/uncategorized\" target=\"_blank\">https://wandb.ai/jotaro/uncategorized</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/jotaro/uncategorized/runs/2qssoew8\" target=\"_blank\">https://wandb.ai/jotaro/uncategorized/runs/2qssoew8</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210222_230615-2qssoew8</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJqqQ8HZ4jkN"
      },
      "source": [
        "class CharacterTable(object):\n",
        "    def __init__(self, chars):\n",
        "\n",
        "        self.chars = sorted(set(chars)) #set of character contained in chars\n",
        "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
        "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
        "    \n",
        "    # encodeする\n",
        "    def encode(self, C, num_rows):\n",
        "        x = np.zeros((num_rows, len(self.chars)))\n",
        "        for i, c in enumerate(C):\n",
        "            x[i, self.char_indices[c]] = 1.0\n",
        "        return x\n",
        "    \n",
        "    def decode(self, x, calc_argmax=True):\n",
        "        if(calc_argmax):\n",
        "            x = x.argmax(axis=-1)\n",
        "        return ''.join(self.indices_char[x] for x in x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkGfh9UD4jkO"
      },
      "source": [
        "config.training_size = 4000\n",
        "config.digits = 2\n",
        "config.hidden_size = 100\n",
        "config.batch_size = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ze8byayi4jkP"
      },
      "source": [
        "# Parameters for the model and dataset.\n",
        "config.training_size = 200\n",
        "config.digits = 1\n",
        "config.hidden_size = 128\n",
        "config.batch_size = 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8BR3hAh4jkP"
      },
      "source": [
        "chars = '0123456789+- '\n",
        "ctable = CharacterTable(chars)\n",
        "maxlen = config.digits + 1 + config.digits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPTVau2l4jkQ"
      },
      "source": [
        "questions = []\n",
        "expected = []\n",
        "seen = set()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyN-Y8Kb4jkQ",
        "outputId": "fb03c82e-4d6c-4aed-91ca-733fd335a37f"
      },
      "source": [
        "print('generating data')\n",
        "while len(questions) < config.training_size:\n",
        "    f = lambda: int(''.join(np.random.choice(list('0123456789'))for i in range(np.random.randint(1, config.digits+1))))\n",
        "    a, b = f(), f()\n",
        "    key = tuple(sorted((a, b)))\n",
        "    if key in seen:\n",
        "        continue\n",
        "    seen.add(key)\n",
        "    q = '{}-{}'.format(a,b)\n",
        "    query = q + ' ' * (maxlen - len(q))\n",
        "    ans = str(a-b)\n",
        "    ans += ' ' * (config.digits + 1 - len(ans))\n",
        "    questions.append(query)\n",
        "    expected.append(ans)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "generating data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npyiQbxc4jkR",
        "outputId": "1740c870-439e-4cd5-eadf-44a67d53e484"
      },
      "source": [
        "print('Total addition questions:', len(questions))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total addition questions: 4000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFD1V9Pn4jkR",
        "outputId": "08ea1d66-23bc-4d2e-fe36-278d54b124bf"
      },
      "source": [
        "print('Vectorization...')\n",
        "x = np.zeros((len(questions), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(questions), config.digits + 1, len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(questions):\n",
        "    x[i] = ctable.encode(sentence, maxlen)\n",
        "for i, sentence in enumerate(expected):\n",
        "    y[i] = ctable.encode(sentence, config.digits + 1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vectorization...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2RfPyDk4jkS"
      },
      "source": [
        "# Explicitly set apart 10% for validation data that we never train over.\n",
        "split_at = len(x) - len(x) // 10\n",
        "(x_train, x_val) = x[:split_at], x[split_at:]\n",
        "(y_train, y_val) = y[:split_at], y[split_at:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjMjwgNY4jkS",
        "outputId": "bd523a0d-613b-4770-d940-78b01ee7af04"
      },
      "source": [
        "model = Sequential()\n",
        "#encoder\n",
        "model.add(LSTM(config.hidden_size, input_shape=(maxlen, len(chars)))) #input_shape = (len_chars, len_vector)\n",
        "model.add(RepeatVector(config.digits+1))\n",
        "#decoder\n",
        "model.add(LSTM(config.hidden_size, return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(len(chars), activation = 'softmax')))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 100)               45600     \n",
            "_________________________________________________________________\n",
            "repeat_vector (RepeatVector) (None, 3, 100)            0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 3, 100)            80400     \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 3, 13)             1313      \n",
            "=================================================================\n",
            "Total params: 127,313\n",
            "Trainable params: 127,313\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "outputPrepend"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQN4Auir4jkT",
        "outputId": "971a8e1f-e6d6-4602-d078-47c8a9c15452"
      },
      "source": [
        "for iteration in range(1, 200):\n",
        "    print()\n",
        "    print('-' * 50)\n",
        "    print('Iteration', iteration)\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=config.batch_size,\n",
        "              epochs=1,\n",
        "              validation_data=(x_val, y_val),callbacks=[WandbCallback()])\n",
        "    # Select 10 samples from the validation set at random so we can visualize\n",
        "    # errors.\n",
        "    for i in range(10):\n",
        "        ind = np.random.randint(0, len(x_val))\n",
        "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
        "        preds = model.predict_classes(rowx, verbose=0)\n",
        "        q = ctable.decode(rowx[0])\n",
        "        correct = ctable.decode(rowy[0])\n",
        "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
        "        print('Q', q, end=' ')\n",
        "        print('A', correct, end=' ')\n",
        "        if correct == guess:\n",
        "            print('✅', end=' ')\n",
        "        else:\n",
        "            print('❌', end=' ')\n",
        "        print(guess)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "--------------------------------------------------\n",
            "Iteration 1\n",
            "36/36 [==============================] - 4s 50ms/step - loss: 2.4832 - accuracy: 0.2027 - val_loss: 2.2377 - val_accuracy: 0.2275\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Q 31-47 A -16 ❌    \n",
            "Q 54-33 A 21  ❌    \n",
            "Q 38-80 A -42 ❌    \n",
            "Q 60-63 A -3  ❌    \n",
            "Q 57-22 A 35  ❌    \n",
            "Q 75-16 A 59  ❌    \n",
            "Q 46-90 A -44 ❌    \n",
            "Q 64-12 A 52  ❌    \n",
            "Q 33-42 A -9  ❌    \n",
            "Q 37-94 A -57 ❌    \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 2\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 2.1290 - accuracy: 0.3343 - val_loss: 1.9549 - val_accuracy: 0.3933\n",
            "Q 65-17 A 48  ❌ -4 \n",
            "Q 43-10 A 33  ❌ -4 \n",
            "Q 50-34 A 16  ❌ -4 \n",
            "Q 51-14 A 37  ❌ -4 \n",
            "Q 17-46 A -29 ❌ -4 \n",
            "Q 41-68 A -27 ❌ -4 \n",
            "Q 67-66 A 1   ❌ -4 \n",
            "Q 24-90 A -66 ❌ -4 \n",
            "Q 51-14 A 37  ❌ -4 \n",
            "Q 64-12 A 52  ❌ -4 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 3\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 1.9395 - accuracy: 0.3982 - val_loss: 1.9011 - val_accuracy: 0.4108\n",
            "Q 54-54 A 0   ❌ -1 \n",
            "Q 26-74 A -48 ❌ -1 \n",
            "Q 79-81 A -2  ❌ -1 \n",
            "Q 43-58 A -15 ❌ -1 \n",
            "Q 51-14 A 37  ❌ -1 \n",
            "Q 52-36 A 16  ❌ -1 \n",
            "Q 71-91 A -20 ❌ -1 \n",
            "Q 87-79 A 8   ❌ -1 \n",
            "Q 87-61 A 26  ❌ -1 \n",
            "Q 11-12 A -1  ✅ -1 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 4\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 1.8859 - accuracy: 0.4005 - val_loss: 1.8150 - val_accuracy: 0.4108\n",
            "Q 48-99 A -51 ❌ -1 \n",
            "Q 11-12 A -1  ❌ -  \n",
            "Q 27-42 A -15 ❌ -1 \n",
            "Q 66-56 A 10  ❌ -  \n",
            "Q 93-78 A 15  ❌ -1 \n",
            "Q 47-97 A -50 ❌ -1 \n",
            "Q 52-11 A 41  ❌ -  \n",
            "Q 65-80 A -15 ❌ -1 \n",
            "Q 12-48 A -36 ❌ -1 \n",
            "Q 32-60 A -28 ❌ -1 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 5\n",
            "36/36 [==============================] - 1s 27ms/step - loss: 1.8138 - accuracy: 0.4067 - val_loss: 1.7167 - val_accuracy: 0.3983\n",
            "Q 72-64 A 8   ❌ -2 \n",
            "Q 65-32 A 33  ❌ -  \n",
            "Q 77-12 A 65  ❌ -  \n",
            "Q 91-54 A 37  ❌ -  \n",
            "Q 97-60 A 37  ❌ -  \n",
            "Q 39-55 A -16 ❌ -2 \n",
            "Q 34-46 A -12 ❌ -2 \n",
            "Q 55-59 A -4  ❌ -2 \n",
            "Q 20-65 A -45 ❌ -2 \n",
            "Q 31-83 A -52 ❌ -2 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 6\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 1.7453 - accuracy: 0.4052 - val_loss: 1.6598 - val_accuracy: 0.4142\n",
            "Q 41-73 A -32 ❌ -2 \n",
            "Q 35-15 A 20  ❌ -2 \n",
            "Q 27-13 A 14  ❌ -2 \n",
            "Q 52-79 A -27 ❌ -44\n",
            "Q 48-87 A -39 ❌ -47\n",
            "Q 31-92 A -61 ❌ -44\n",
            "Q 16-29 A -13 ❌ -2 \n",
            "Q 52-36 A 16  ❌ -2 \n",
            "Q 31-81 A -50 ❌ -44\n",
            "Q 29-50 A -21 ❌ -4 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 7\n",
            "36/36 [==============================] - 1s 28ms/step - loss: 1.6892 - accuracy: 0.4108 - val_loss: 1.6123 - val_accuracy: 0.4342\n",
            "Q 69-65 A 4   ❌ -1 \n",
            "Q 51-14 A 37  ❌ 1  \n",
            "Q 77-67 A 10  ❌ -1 \n",
            "Q 23-10 A 13  ❌ 11 \n",
            "Q 73-78 A -5  ❌ -1 \n",
            "Q 27-13 A 14  ❌ -1 \n",
            "Q 32-60 A -28 ❌ -1 \n",
            "Q 99-17 A 82  ❌ 1  \n",
            "Q 19-49 A -30 ❌ -50\n",
            "Q 63-23 A 40  ❌ 1  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 8\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 1.6238 - accuracy: 0.4210 - val_loss: 1.5601 - val_accuracy: 0.4375\n",
            "Q 40-11 A 29  ❌ 11 \n",
            "Q 74-51 A 23  ❌ 11 \n",
            "Q 94-66 A 28  ❌ 1  \n",
            "Q 86-11 A 75  ❌ 1  \n",
            "Q 64-12 A 52  ❌ 1  \n",
            "Q 39-46 A -7  ❌ -1 \n",
            "Q 62-77 A -15 ❌ -2 \n",
            "Q 73-43 A 30  ❌ 11 \n",
            "Q 26-68 A -42 ❌ -21\n",
            "Q 36-33 A 3   ❌ -1 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 9\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 1.5619 - accuracy: 0.4310 - val_loss: 1.5045 - val_accuracy: 0.4500\n",
            "Q 47-60 A -13 ❌ -1 \n",
            "Q 65-87 A -22 ❌ -2 \n",
            "Q 95-27 A 68  ❌ 4  \n",
            "Q 79-81 A -2  ❌ -1 \n",
            "Q 44-96 A -52 ❌ -42\n",
            "Q 53-69 A -16 ❌ -2 \n",
            "Q 27-90 A -63 ❌ -42\n",
            "Q 53-73 A -20 ❌ -2 \n",
            "Q 62-95 A -33 ❌ -23\n",
            "Q 63-26 A 37  ❌ 1  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 10\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 1.5079 - accuracy: 0.4496 - val_loss: 1.4574 - val_accuracy: 0.4800\n",
            "Q 98-51 A 47  ✅ 47 \n",
            "Q 63-74 A -11 ❌ -1 \n",
            "Q 72-85 A -13 ❌ -1 \n",
            "Q 65-65 A 0   ❌ -1 \n",
            "Q 57-83 A -26 ❌ -10\n",
            "Q 34-25 A 9   ❌ -1 \n",
            "Q 27-90 A -63 ❌ -69\n",
            "Q 88-95 A -7  ❌ -1 \n",
            "Q 31-28 A 3   ❌ -1 \n",
            "Q 55-70 A -15 ❌ -10\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 11\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 1.4655 - accuracy: 0.4699 - val_loss: 1.4333 - val_accuracy: 0.4600\n",
            "Q 99-31 A 68  ❌ 46 \n",
            "Q 66-45 A 21  ❌ 1  \n",
            "Q 38-27 A 11  ❌ -  \n",
            "Q 58-57 A 1   ❌ -1 \n",
            "Q 66-33 A 33  ❌ 2  \n",
            "Q 37-63 A -26 ❌ -22\n",
            "Q 41-68 A -27 ❌ -22\n",
            "Q 35-46 A -11 ❌ -21\n",
            "Q 14-71 A -57 ❌ -44\n",
            "Q 60-63 A -3  ❌ -1 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 12\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 1.4423 - accuracy: 0.4841 - val_loss: 1.4505 - val_accuracy: 0.5192\n",
            "Q 43-23 A 20  ❌ 1  \n",
            "Q 34-25 A 9   ❌ 1  \n",
            "Q 96-46 A 50  ❌ 46 \n",
            "Q 47-57 A -10 ❌ -1 \n",
            "Q 31-23 A 8   ❌ 1  \n",
            "Q 73-32 A 41  ❌ 46 \n",
            "Q 72-85 A -13 ❌ -1 \n",
            "Q 29-50 A -21 ❌ -2 \n",
            "Q 54-14 A 40  ❌ 45 \n",
            "Q 80-21 A 59  ❌ 46 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 13\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 1.4065 - accuracy: 0.5052 - val_loss: 1.3736 - val_accuracy: 0.5058\n",
            "Q 26-74 A -48 ❌ -45\n",
            "Q 52-11 A 41  ❌ 45 \n",
            "Q 85-63 A 22  ❌ 11 \n",
            "Q 74-61 A 13  ❌ 11 \n",
            "Q 36-31 A 5   ❌ 1  \n",
            "Q 63-26 A 37  ❌ 11 \n",
            "Q 26-79 A -53 ❌ -45\n",
            "Q 26-68 A -42 ❌ -35\n",
            "Q 35-46 A -11 ❌ -1 \n",
            "Q 60-71 A -11 ❌ -1 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 14\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 1.3829 - accuracy: 0.5205 - val_loss: 1.3378 - val_accuracy: 0.5400\n",
            "Q 16-70 A -54 ❌ -59\n",
            "Q 34-56 A -22 ❌ -21\n",
            "Q 77-29 A 48  ❌ 49 \n",
            "Q 64-12 A 52  ❌ 49 \n",
            "Q 98-51 A 47  ❌ 49 \n",
            "Q 63-17 A 46  ❌ 29 \n",
            "Q 52-36 A 16  ❌ 1  \n",
            "Q 98-74 A 24  ❌ 27 \n",
            "Q 53-48 A 5   ❌ 1  \n",
            "Q 11-24 A -13 ❌ -1 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 15\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 1.3651 - accuracy: 0.5270 - val_loss: 1.3533 - val_accuracy: 0.5450\n",
            "Q 80-54 A 26  ❌ 1  \n",
            "Q 77-39 A 38  ❌ 1  \n",
            "Q 45-70 A -25 ❌ -27\n",
            "Q 90-99 A -9  ❌ -1 \n",
            "Q 59-14 A 45  ❌ 47 \n",
            "Q 14-31 A -17 ❌ -20\n",
            "Q 15-63 A -48 ❌ -43\n",
            "Q 68-14 A 54  ❌ 47 \n",
            "Q 50-33 A 17  ❌ 1  \n",
            "Q 36-31 A 5   ❌ -  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 16\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 1.3476 - accuracy: 0.5341 - val_loss: 1.3017 - val_accuracy: 0.5583\n",
            "Q 28-39 A -11 ❌ -1 \n",
            "Q 86-14 A 72  ❌ 47 \n",
            "Q 71-26 A 45  ❌ 20 \n",
            "Q 34-56 A -22 ✅ -22\n",
            "Q 49-21 A 28  ❌ 20 \n",
            "Q 33-70 A -37 ❌ -33\n",
            "Q 77-12 A 65  ❌ 47 \n",
            "Q 37-63 A -26 ❌ -22\n",
            "Q 81-91 A -10 ❌ -1 \n",
            "Q 64-12 A 52  ❌ 40 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 17\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 1.3248 - accuracy: 0.5436 - val_loss: 1.3231 - val_accuracy: 0.5650\n",
            "Q 31-81 A -50 ❌ -46\n",
            "Q 37-85 A -48 ❌ -46\n",
            "Q 20-65 A -45 ❌ -46\n",
            "Q 65-65 A 0   ❌ -1 \n",
            "Q 69-30 A 39  ❌ 36 \n",
            "Q 30-34 A -4  ❌ -1 \n",
            "Q 47-55 A -8  ❌ -11\n",
            "Q 50-38 A 12  ❌ 1  \n",
            "Q 11-29 A -18 ❌ -26\n",
            "Q 76-85 A -9  ❌ -11\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 18\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 1.3179 - accuracy: 0.5425 - val_loss: 1.2791 - val_accuracy: 0.5725\n",
            "Q 69-41 A 28  ❌ 34 \n",
            "Q 38-61 A -23 ❌ -27\n",
            "Q 35-46 A -11 ❌ -1 \n",
            "Q 11-24 A -13 ❌ -20\n",
            "Q 96-78 A 18  ❌ 1  \n",
            "Q 64-12 A 52  ❌ 46 \n",
            "Q 54-33 A 21  ❌ 1  \n",
            "Q 16-48 A -32 ❌ -36\n",
            "Q 54-14 A 40  ❌ 34 \n",
            "Q 57-55 A 2   ❌ -  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 19\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 1.3032 - accuracy: 0.5492 - val_loss: 1.2666 - val_accuracy: 0.5742\n",
            "Q 24-32 A -8  ❌ -1 \n",
            "Q 37-85 A -48 ❌ -43\n",
            "Q 27-90 A -63 ✅ -63\n",
            "Q 41-37 A 4   ❌ 1  \n",
            "Q 88-65 A 23  ❌ 37 \n",
            "Q 36-31 A 5   ❌ 1  \n",
            "Q 91-86 A 5   ❌ 1  \n",
            "Q 98-63 A 35  ❌ 47 \n",
            "Q 62-37 A 25  ❌ 21 \n",
            "Q 36-23 A 13  ❌ 1  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 20\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 1.2827 - accuracy: 0.5583 - val_loss: 1.2749 - val_accuracy: 0.5717\n",
            "Q 17-46 A -29 ❌ -26\n",
            "Q 31-12 A 19  ❌ 10 \n",
            "Q 62-42 A 20  ✅ 20 \n",
            "Q 54-33 A 21  ❌ 30 \n",
            "Q 96-78 A 18  ❌ 20 \n",
            "Q 44-90 A -46 ❌ -33\n",
            "Q 79-81 A -2  ❌ -  \n",
            "Q 36-23 A 13  ❌ 2  \n",
            "Q 55-70 A -15 ❌ -1 \n",
            "Q 73-43 A 30  ✅ 30 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 21\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 1.2832 - accuracy: 0.5542 - val_loss: 1.2463 - val_accuracy: 0.5925\n",
            "Q 71-80 A -9  ❌ -1 \n",
            "Q 31-15 A 16  ❌ 1  \n",
            "Q 31-47 A -16 ❌ -11\n",
            "Q 52-60 A -8  ❌ -1 \n",
            "Q 64-61 A 3   ❌ 1  \n",
            "Q 72-14 A 58  ❌ 46 \n",
            "Q 71-80 A -9  ❌ -1 \n",
            "Q 47-84 A -37 ❌ -33\n",
            "Q 44-27 A 17  ❌ 1  \n",
            "Q 64-12 A 52  ❌ 46 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 22\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 1.2568 - accuracy: 0.5632 - val_loss: 1.2204 - val_accuracy: 0.5800\n",
            "Q 69-83 A -14 ❌ -11\n",
            "Q 34-57 A -23 ❌ -25\n",
            "Q 31-92 A -61 ❌ -55\n",
            "Q 39-96 A -57 ❌ -55\n",
            "Q 71-42 A 29  ❌ 26 \n",
            "Q 22-88 A -66 ❌ -65\n",
            "Q 76-57 A 19  ❌ 11 \n",
            "Q 59-50 A 9   ❌ 1  \n",
            "Q 76-57 A 19  ❌ 11 \n",
            "Q 46-40 A 6   ❌ 1  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 23\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 1.2386 - accuracy: 0.5722 - val_loss: 1.2121 - val_accuracy: 0.6025\n",
            "Q 87-61 A 26  ❌ 42 \n",
            "Q 31-23 A 8   ❌ 1  \n",
            "Q 40-10 A 30  ❌ 22 \n",
            "Q 63-17 A 46  ❌ 42 \n",
            "Q 98-63 A 35  ❌ 49 \n",
            "Q 80-45 A 35  ❌ 22 \n",
            "Q 73-78 A -5  ❌ -1 \n",
            "Q 60-34 A 26  ❌ 22 \n",
            "Q 63-74 A -11 ✅ -11\n",
            "Q 67-86 A -19 ❌ -11\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 24\n",
            "36/36 [==============================] - 1s 29ms/step - loss: 1.2257 - accuracy: 0.5776 - val_loss: 1.2072 - val_accuracy: 0.5825\n",
            "Q 87-79 A 8   ❌ 1  \n",
            "Q 40-11 A 29  ❌ 31 \n",
            "Q 26-68 A -42 ❌ -33\n",
            "Q 64-82 A -18 ❌ -11\n",
            "Q 20-42 A -22 ❌ -11\n",
            "Q 90-41 A 49  ❌ 58 \n",
            "Q 77-12 A 65  ❌ 68 \n",
            "Q 11-24 A -13 ❌ -10\n",
            "Q 24-33 A -9  ❌ -1 \n",
            "Q 34-44 A -10 ❌ -1 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 25\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 1.2320 - accuracy: 0.5667 - val_loss: 1.2037 - val_accuracy: 0.6000\n",
            "Q 53-63 A -10 ❌ -1 \n",
            "Q 52-36 A 16  ❌ 12 \n",
            "Q 71-91 A -20 ❌ -10\n",
            "Q 72-14 A 58  ❌ 46 \n",
            "Q 55-70 A -15 ❌ -11\n",
            "Q 33-48 A -15 ❌ -10\n",
            "Q 80-54 A 26  ❌ 22 \n",
            "Q 27-96 A -69 ❌ -60\n",
            "Q 27-90 A -63 ❌ -60\n",
            "Q 36-28 A 8   ❌ 1  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 26\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 1.2029 - accuracy: 0.5853 - val_loss: 1.1767 - val_accuracy: 0.6083\n",
            "Q 64-12 A 52  ❌ 42 \n",
            "Q 23-54 A -31 ❌ -38\n",
            "Q 50-34 A 16  ❌ 1  \n",
            "Q 44-21 A 23  ❌ 22 \n",
            "Q 48-69 A -21 ❌ -28\n",
            "Q 35-47 A -12 ❌ -1 \n",
            "Q 43-10 A 33  ❌ 22 \n",
            "Q 96-46 A 50  ❌ 48 \n",
            "Q 88-95 A -7  ❌ -1 \n",
            "Q 63-17 A 46  ❌ 42 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 27\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 1.1896 - accuracy: 0.5887 - val_loss: 1.1703 - val_accuracy: 0.6133\n",
            "Q 31-28 A 3   ❌ 1  \n",
            "Q 16-70 A -54 ❌ -53\n",
            "Q 72-64 A 8   ❌ 1  \n",
            "Q 75-16 A 59  ❌ 56 \n",
            "Q 30-26 A 4   ❌ 1  \n",
            "Q 31-92 A -61 ❌ -65\n",
            "Q 76-51 A 25  ❌ 39 \n",
            "Q 42-93 A -51 ❌ -43\n",
            "Q 52-13 A 39  ❌ 46 \n",
            "Q 33-42 A -9  ❌ -1 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 28\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 1.1831 - accuracy: 0.5931 - val_loss: 1.1519 - val_accuracy: 0.6117\n",
            "Q 55-70 A -15 ❌ -11\n",
            "Q 58-82 A -24 ❌ -27\n",
            "Q 21-63 A -42 ❌ -43\n",
            "Q 60-63 A -3  ❌ -  \n",
            "Q 99-37 A 62  ❌ 77 \n",
            "Q 26-98 A -72 ❌ -73\n",
            "Q 55-70 A -15 ❌ -11\n",
            "Q 86-14 A 72  ❌ 67 \n",
            "Q 94-38 A 56  ❌ 57 \n",
            "Q 68-83 A -15 ❌ -10\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 29\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 1.1742 - accuracy: 0.5914 - val_loss: 1.1575 - val_accuracy: 0.6300\n",
            "Q 31-57 A -26 ❌ -27\n",
            "Q 16-94 A -78 ❌ -76\n",
            "Q 69-83 A -14 ❌ -10\n",
            "Q 61-77 A -16 ❌ -10\n",
            "Q 28-52 A -24 ❌ -27\n",
            "Q 96-78 A 18  ❌ 1  \n",
            "Q 42-46 A -4  ❌ -1 \n",
            "Q 34-24 A 10  ❌ 1  \n",
            "Q 82-41 A 41  ❌ 40 \n",
            "Q 21-63 A -42 ❌ -43\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 30\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 1.1532 - accuracy: 0.6009 - val_loss: 1.1361 - val_accuracy: 0.6225\n",
            "Q 24-90 A -66 ❌ -65\n",
            "Q 99-37 A 62  ❌ 67 \n",
            "Q 72-35 A 37  ❌ 39 \n",
            "Q 77-39 A 38  ❌ 39 \n",
            "Q 96-78 A 18  ❌ 22 \n",
            "Q 74-51 A 23  ❌ 32 \n",
            "Q 13-56 A -43 ✅ -43\n",
            "Q 40-11 A 29  ❌ 32 \n",
            "Q 84-96 A -12 ❌ -11\n",
            "Q 45-99 A -54 ❌ -53\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 31\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 1.1442 - accuracy: 0.5994 - val_loss: 1.1233 - val_accuracy: 0.6283\n",
            "Q 52-11 A 41  ❌ 42 \n",
            "Q 26-83 A -57 ❌ -55\n",
            "Q 72-35 A 37  ❌ 32 \n",
            "Q 14-34 A -20 ❌ -27\n",
            "Q 48-69 A -21 ❌ -27\n",
            "Q 13-30 A -17 ❌ -10\n",
            "Q 72-35 A 37  ❌ 32 \n",
            "Q 45-70 A -25 ❌ -26\n",
            "Q 42-83 A -41 ❌ -46\n",
            "Q 36-28 A 8   ❌ 1  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 32\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 1.1355 - accuracy: 0.6070 - val_loss: 1.1740 - val_accuracy: 0.5967\n",
            "Q 22-88 A -66 ❌ -65\n",
            "Q 54-33 A 21  ❌ 34 \n",
            "Q 41-95 A -54 ❌ -43\n",
            "Q 81-97 A -16 ❌ -10\n",
            "Q 58-53 A 5   ❌ 1  \n",
            "Q 52-47 A 5   ❌ 1  \n",
            "Q 55-11 A 44  ✅ 44 \n",
            "Q 20-42 A -22 ❌ -27\n",
            "Q 38-80 A -42 ❌ -43\n",
            "Q 81-97 A -16 ❌ -10\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 33\n",
            "36/36 [==============================] - 1s 22ms/step - loss: 1.1271 - accuracy: 0.6092 - val_loss: 1.1159 - val_accuracy: 0.6342\n",
            "Q 70-71 A -1  ❌ -  \n",
            "Q 54-14 A 40  ❌ 34 \n",
            "Q 31-92 A -61 ❌ -60\n",
            "Q 34-19 A 15  ❌ 14 \n",
            "Q 60-31 A 29  ❌ 22 \n",
            "Q 47-97 A -50 ❌ -43\n",
            "Q 34-56 A -22 ❌ -21\n",
            "Q 65-64 A 1   ✅ 1  \n",
            "Q 79-23 A 56  ❌ 57 \n",
            "Q 80-82 A -2  ❌ -  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 34\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 1.1141 - accuracy: 0.6146 - val_loss: 1.0987 - val_accuracy: 0.6408\n",
            "Q 89-54 A 35  ❌ 49 \n",
            "Q 44-75 A -31 ❌ -36\n",
            "Q 71-34 A 37  ❌ 21 \n",
            "Q 21-63 A -42 ❌ -43\n",
            "Q 43-58 A -15 ❌ -11\n",
            "Q 18-88 A -70 ❌ -76\n",
            "Q 53-69 A -16 ❌ -11\n",
            "Q 86-99 A -13 ❌ -10\n",
            "Q 76-16 A 60  ❌ 56 \n",
            "Q 21-66 A -45 ❌ -41\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 35\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 1.1112 - accuracy: 0.6118 - val_loss: 1.0936 - val_accuracy: 0.6308\n",
            "Q 36-31 A 5   ❌ 1  \n",
            "Q 74-29 A 45  ❌ 46 \n",
            "Q 60-34 A 26  ❌ 36 \n",
            "Q 43-21 A 22  ❌ 26 \n",
            "Q 66-56 A 10  ❌ 1  \n",
            "Q 59-14 A 45  ❌ 56 \n",
            "Q 19-62 A -43 ✅ -43\n",
            "Q 26-60 A -34 ❌ -36\n",
            "Q 33-77 A -44 ❌ -43\n",
            "Q 54-64 A -10 ❌ -1 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 36\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 1.0977 - accuracy: 0.6170 - val_loss: 1.0764 - val_accuracy: 0.6525\n",
            "Q 70-11 A 59  ❌ 66 \n",
            "Q 21-46 A -25 ❌ -26\n",
            "Q 84-33 A 51  ❌ 46 \n",
            "Q 31-81 A -50 ❌ -55\n",
            "Q 86-54 A 32  ❌ 36 \n",
            "Q 74-29 A 45  ❌ 46 \n",
            "Q 82-41 A 41  ❌ 46 \n",
            "Q 32-60 A -28 ❌ -26\n",
            "Q 55-70 A -15 ❌ -11\n",
            "Q 44-75 A -31 ❌ -36\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 37\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 1.0858 - accuracy: 0.6208 - val_loss: 1.0733 - val_accuracy: 0.6383\n",
            "Q 60-51 A 9   ❌ 1  \n",
            "Q 44-96 A -52 ❌ -43\n",
            "Q 26-98 A -72 ❌ -63\n",
            "Q 44-79 A -35 ❌ -33\n",
            "Q 72-62 A 10  ❌ 1  \n",
            "Q 31-23 A 8   ❌ 1  \n",
            "Q 87-61 A 26  ❌ 31 \n",
            "Q 14-92 A -78 ❌ -73\n",
            "Q 93-76 A 17  ❌ 11 \n",
            "Q 38-27 A 11  ❌ 1  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 38\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 1.0766 - accuracy: 0.6236 - val_loss: 1.0646 - val_accuracy: 0.6467\n",
            "Q 47-55 A -8  ❌ -1 \n",
            "Q 11-12 A -1  ❌ -  \n",
            "Q 38-80 A -42 ❌ -43\n",
            "Q 33-77 A -44 ❌ -43\n",
            "Q 80-21 A 59  ❌ 57 \n",
            "Q 72-62 A 10  ❌ 1  \n",
            "Q 14-12 A 2   ❌ 1  \n",
            "Q 72-64 A 8   ❌ 1  \n",
            "Q 47-57 A -10 ❌ -11\n",
            "Q 15-13 A 2   ❌ -  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 39\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 1.0726 - accuracy: 0.6258 - val_loss: 1.0604 - val_accuracy: 0.6550\n",
            "Q 87-79 A 8   ❌ 1  \n",
            "Q 76-16 A 60  ❌ 52 \n",
            "Q 14-31 A -17 ❌ -10\n",
            "Q 81-97 A -16 ❌ -10\n",
            "Q 14-71 A -57 ❌ -50\n",
            "Q 55-11 A 44  ❌ 42 \n",
            "Q 81-32 A 49  ❌ 41 \n",
            "Q 53-63 A -10 ❌ -1 \n",
            "Q 42-46 A -4  ❌ -1 \n",
            "Q 88-76 A 12  ❌ 1  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 40\n",
            "36/36 [==============================] - 1s 22ms/step - loss: 1.0715 - accuracy: 0.6234 - val_loss: 1.0632 - val_accuracy: 0.6467\n",
            "Q 24-32 A -8  ❌ -1 \n",
            "Q 72-62 A 10  ❌ 1  \n",
            "Q 38-21 A 17  ❌ 10 \n",
            "Q 32-61 A -29 ❌ -26\n",
            "Q 13-30 A -17 ❌ -10\n",
            "Q 11-19 A -8  ❌ -1 \n",
            "Q 80-39 A 41  ❌ 39 \n",
            "Q 26-60 A -34 ❌ -26\n",
            "Q 85-63 A 22  ❌ 30 \n",
            "Q 24-33 A -9  ❌ -1 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 41\n",
            "36/36 [==============================] - 1s 28ms/step - loss: 1.0814 - accuracy: 0.6191 - val_loss: 1.1926 - val_accuracy: 0.5800\n",
            "Q 33-56 A -23 ❌ -15\n",
            "Q 80-45 A 35  ❌ 39 \n",
            "Q 13-56 A -43 ✅ -43\n",
            "Q 45-99 A -54 ❌ -48\n",
            "Q 76-83 A -7  ❌ -1 \n",
            "Q 77-67 A 10  ❌ 1  \n",
            "Q 81-91 A -10 ❌ -1 \n",
            "Q 48-99 A -51 ❌ -48\n",
            "Q 15-13 A 2   ❌ 1  \n",
            "Q 93-78 A 15  ❌ 14 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 42\n",
            "36/36 [==============================] - 1s 22ms/step - loss: 1.0593 - accuracy: 0.6272 - val_loss: 1.0815 - val_accuracy: 0.6467\n",
            "Q 70-71 A -1  ✅ -1 \n",
            "Q 58-23 A 35  ❌ 30 \n",
            "Q 38-61 A -23 ❌ -26\n",
            "Q 21-30 A -9  ❌ -1 \n",
            "Q 94-14 A 80  ❌ 63 \n",
            "Q 65-53 A 12  ❌ 1  \n",
            "Q 24-33 A -9  ❌ -1 \n",
            "Q 33-56 A -23 ❌ -26\n",
            "Q 14-75 A -61 ❌ -60\n",
            "Q 71-91 A -20 ❌ -27\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 43\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 1.0469 - accuracy: 0.6329 - val_loss: 1.0557 - val_accuracy: 0.6308\n",
            "Q 72-85 A -13 ❌ -10\n",
            "Q 45-22 A 23  ❌ 22 \n",
            "Q 67-90 A -23 ❌ -24\n",
            "Q 81-97 A -16 ❌ -10\n",
            "Q 77-29 A 48  ❌ 47 \n",
            "Q 69-91 A -22 ❌ -23\n",
            "Q 99-39 A 60  ❌ 67 \n",
            "Q 86-11 A 75  ❌ 77 \n",
            "Q 43-58 A -15 ❌ -17\n",
            "Q 96-57 A 39  ❌ 49 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 44\n",
            "36/36 [==============================] - 1s 22ms/step - loss: 1.0360 - accuracy: 0.6390 - val_loss: 1.0322 - val_accuracy: 0.6467\n",
            "Q 72-64 A 8   ❌ 1  \n",
            "Q 96-46 A 50  ❌ 49 \n",
            "Q 32-60 A -28 ❌ -23\n",
            "Q 53-63 A -10 ❌ -1 \n",
            "Q 37-63 A -26 ❌ -23\n",
            "Q 13-67 A -54 ❌ -53\n",
            "Q 89-25 A 64  ❌ 67 \n",
            "Q 55-11 A 44  ❌ 43 \n",
            "Q 16-29 A -13 ✅ -13\n",
            "Q 54-33 A 21  ❌ 32 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 45\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 1.0386 - accuracy: 0.6351 - val_loss: 1.0397 - val_accuracy: 0.6458\n",
            "Q 45-22 A 23  ❌ 22 \n",
            "Q 62-37 A 25  ❌ 21 \n",
            "Q 75-80 A -5  ❌ -1 \n",
            "Q 98-51 A 47  ❌ 59 \n",
            "Q 57-55 A 2   ❌ -  \n",
            "Q 14-70 A -56 ❌ -50\n",
            "Q 53-63 A -10 ❌ -11\n",
            "Q 27-13 A 14  ❌ 12 \n",
            "Q 33-42 A -9  ❌ -1 \n",
            "Q 87-44 A 43  ❌ 49 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 46\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 1.0212 - accuracy: 0.6439 - val_loss: 1.0230 - val_accuracy: 0.6467\n",
            "Q 98-74 A 24  ❌ 29 \n",
            "Q 26-68 A -42 ❌ -43\n",
            "Q 70-71 A -1  ❌ -  \n",
            "Q 35-91 A -56 ❌ -53\n",
            "Q 60-71 A -11 ✅ -11\n",
            "Q 79-81 A -2  ❌ -  \n",
            "Q 96-46 A 50  ❌ 47 \n",
            "Q 30-62 A -32 ❌ -26\n",
            "Q 81-74 A 7   ❌ 1  \n",
            "Q 69-91 A -22 ❌ -27\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 47\n",
            "36/36 [==============================] - 1s 22ms/step - loss: 1.0124 - accuracy: 0.6444 - val_loss: 1.0113 - val_accuracy: 0.6542\n",
            "Q 99-37 A 62  ❌ 69 \n",
            "Q 93-76 A 17  ❌ 11 \n",
            "Q 24-90 A -66 ❌ -61\n",
            "Q 42-78 A -36 ✅ -36\n",
            "Q 81-32 A 49  ❌ 56 \n",
            "Q 67-86 A -19 ❌ -21\n",
            "Q 50-38 A 12  ❌ 1  \n",
            "Q 65-35 A 30  ❌ 39 \n",
            "Q 57-55 A 2   ❌ 1  \n",
            "Q 73-78 A -5  ❌ -1 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 48\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 1.0090 - accuracy: 0.6494 - val_loss: 1.0064 - val_accuracy: 0.6583\n",
            "Q 80-54 A 26  ❌ 21 \n",
            "Q 47-60 A -13 ❌ -11\n",
            "Q 38-21 A 17  ❌ 12 \n",
            "Q 31-17 A 14  ❌ 11 \n",
            "Q 26-74 A -48 ✅ -48\n",
            "Q 48-69 A -21 ❌ -26\n",
            "Q 21-46 A -25 ❌ -26\n",
            "Q 95-51 A 44  ✅ 44 \n",
            "Q 13-30 A -17 ❌ -15\n",
            "Q 37-63 A -26 ✅ -26\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 49\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 0.9974 - accuracy: 0.6522 - val_loss: 0.9989 - val_accuracy: 0.6608\n",
            "Q 58-23 A 35  ❌ 34 \n",
            "Q 57-33 A 24  ❌ 22 \n",
            "Q 40-10 A 30  ❌ 22 \n",
            "Q 66-56 A 10  ❌ 1  \n",
            "Q 63-26 A 37  ❌ 39 \n",
            "Q 50-33 A 17  ❌ 12 \n",
            "Q 99-31 A 68  ❌ 77 \n",
            "Q 24-33 A -9  ❌ -1 \n",
            "Q 89-91 A -2  ❌ -  \n",
            "Q 28-52 A -24 ❌ -27\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 50\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 0.9928 - accuracy: 0.6535 - val_loss: 0.9896 - val_accuracy: 0.6675\n",
            "Q 35-89 A -54 ❌ -55\n",
            "Q 68-83 A -15 ❌ -10\n",
            "Q 23-54 A -31 ❌ -34\n",
            "Q 45-19 A 26  ❌ 28 \n",
            "Q 98-74 A 24  ❌ 29 \n",
            "Q 38-21 A 17  ❌ 12 \n",
            "Q 62-48 A 14  ❌ 15 \n",
            "Q 80-41 A 39  ✅ 39 \n",
            "Q 17-46 A -29 ❌ -25\n",
            "Q 80-41 A 39  ✅ 39 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 51\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 0.9853 - accuracy: 0.6535 - val_loss: 0.9943 - val_accuracy: 0.6625\n",
            "Q 69-65 A 4   ❌ 1  \n",
            "Q 14-71 A -57 ❌ -53\n",
            "Q 99-31 A 68  ❌ 77 \n",
            "Q 86-86 A 0   ❌ -  \n",
            "Q 90-41 A 49  ❌ 57 \n",
            "Q 75-52 A 23  ❌ 30 \n",
            "Q 76-83 A -7  ❌ -1 \n",
            "Q 83-64 A 19  ❌ 14 \n",
            "Q 90-99 A -9  ❌ -1 \n",
            "Q 95-51 A 44  ✅ 44 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 52\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 0.9821 - accuracy: 0.6589 - val_loss: 0.9828 - val_accuracy: 0.6742\n",
            "Q 60-31 A 29  ❌ 20 \n",
            "Q 34-44 A -10 ✅ -10\n",
            "Q 71-32 A 39  ❌ 30 \n",
            "Q 53-48 A 5   ❌ 1  \n",
            "Q 38-92 A -54 ❌ -53\n",
            "Q 31-15 A 16  ❌ 12 \n",
            "Q 42-46 A -4  ❌ -1 \n",
            "Q 21-63 A -42 ❌ -40\n",
            "Q 62-38 A 24  ❌ 26 \n",
            "Q 41-11 A 30  ❌ 20 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 53\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 0.9761 - accuracy: 0.6590 - val_loss: 0.9768 - val_accuracy: 0.6633\n",
            "Q 88-65 A 23  ❌ 29 \n",
            "Q 34-26 A 8   ❌ 1  \n",
            "Q 69-65 A 4   ❌ 1  \n",
            "Q 36-23 A 13  ❌ 12 \n",
            "Q 11-19 A -8  ❌ -1 \n",
            "Q 98-85 A 13  ❌ 10 \n",
            "Q 44-75 A -31 ❌ -36\n",
            "Q 44-30 A 14  ❌ 12 \n",
            "Q 31-73 A -42 ❌ -44\n",
            "Q 85-63 A 22  ❌ 39 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 54\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 0.9666 - accuracy: 0.6603 - val_loss: 0.9651 - val_accuracy: 0.6825\n",
            "Q 73-51 A 22  ✅ 22 \n",
            "Q 26-60 A -34 ❌ -33\n",
            "Q 15-51 A -36 ❌ -33\n",
            "Q 84-33 A 51  ❌ 42 \n",
            "Q 96-57 A 39  ❌ 49 \n",
            "Q 89-91 A -2  ❌ -  \n",
            "Q 46-62 A -16 ❌ -11\n",
            "Q 23-54 A -31 ❌ -33\n",
            "Q 36-80 A -44 ❌ -43\n",
            "Q 36-28 A 8   ❌ 1  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 55\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 0.9627 - accuracy: 0.6631 - val_loss: 0.9982 - val_accuracy: 0.6450\n",
            "Q 34-19 A 15  ❌ 12 \n",
            "Q 94-38 A 56  ❌ 57 \n",
            "Q 98-51 A 47  ❌ 59 \n",
            "Q 80-41 A 39  ✅ 39 \n",
            "Q 41-68 A -27 ❌ -25\n",
            "Q 21-66 A -45 ❌ -43\n",
            "Q 41-37 A 4   ❌ 1  \n",
            "Q 98-94 A 4   ❌ 1  \n",
            "Q 57-64 A -7  ❌ -1 \n",
            "Q 35-15 A 20  ❌ 22 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 56\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 0.9784 - accuracy: 0.6549 - val_loss: 0.9852 - val_accuracy: 0.6550\n",
            "Q 98-85 A 13  ❌ 10 \n",
            "Q 49-79 A -30 ❌ -23\n",
            "Q 15-85 A -70 ❌ -73\n",
            "Q 55-99 A -44 ❌ -43\n",
            "Q 63-26 A 37  ❌ 30 \n",
            "Q 81-74 A 7   ❌ 1  \n",
            "Q 97-60 A 37  ❌ 49 \n",
            "Q 67-90 A -23 ✅ -23\n",
            "Q 73-43 A 30  ✅ 30 \n",
            "Q 21-63 A -42 ❌ -43\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 57\n",
            "36/36 [==============================] - 1s 29ms/step - loss: 0.9538 - accuracy: 0.6673 - val_loss: 0.9536 - val_accuracy: 0.6792\n",
            "Q 27-42 A -15 ✅ -15\n",
            "Q 99-17 A 82  ❌ 80 \n",
            "Q 23-10 A 13  ❌ 10 \n",
            "Q 74-61 A 13  ❌ 12 \n",
            "Q 55-99 A -44 ❌ -43\n",
            "Q 82-41 A 41  ❌ 40 \n",
            "Q 13-64 A -51 ❌ -54\n",
            "Q 31-57 A -26 ✅ -26\n",
            "Q 28-52 A -24 ❌ -26\n",
            "Q 35-15 A 20  ✅ 20 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 58\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 0.9551 - accuracy: 0.6656 - val_loss: 0.9489 - val_accuracy: 0.6758\n",
            "Q 34-25 A 9   ❌ 1  \n",
            "Q 54-54 A 0   ❌ 1  \n",
            "Q 89-54 A 35  ❌ 39 \n",
            "Q 42-31 A 11  ❌ 1  \n",
            "Q 16-44 A -28 ❌ -23\n",
            "Q 34-44 A -10 ✅ -10\n",
            "Q 98-51 A 47  ✅ 47 \n",
            "Q 35-47 A -12 ❌ -11\n",
            "Q 48-99 A -51 ❌ -53\n",
            "Q 26-74 A -48 ❌ -40\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 59\n",
            "36/36 [==============================] - 1s 22ms/step - loss: 0.9419 - accuracy: 0.6706 - val_loss: 0.9453 - val_accuracy: 0.6725\n",
            "Q 26-74 A -48 ❌ -43\n",
            "Q 36-28 A 8   ❌ 1  \n",
            "Q 97-35 A 62  ❌ 67 \n",
            "Q 73-78 A -5  ❌ -1 \n",
            "Q 64-82 A -18 ❌ -17\n",
            "Q 16-29 A -13 ❌ -12\n",
            "Q 99-31 A 68  ❌ 77 \n",
            "Q 39-46 A -7  ❌ -1 \n",
            "Q 45-99 A -54 ❌ -53\n",
            "Q 34-26 A 8   ❌ 1  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 60\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 0.9340 - accuracy: 0.6748 - val_loss: 0.9433 - val_accuracy: 0.6675\n",
            "Q 91-54 A 37  ❌ 39 \n",
            "Q 51-14 A 37  ❌ 31 \n",
            "Q 83-67 A 16  ❌ 14 \n",
            "Q 16-94 A -78 ❌ -73\n",
            "Q 16-48 A -32 ❌ -34\n",
            "Q 60-63 A -3  ❌ -1 \n",
            "Q 38-92 A -54 ❌ -53\n",
            "Q 72-37 A 35  ❌ 39 \n",
            "Q 40-11 A 29  ❌ 21 \n",
            "Q 57-33 A 24  ❌ 22 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 61\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 0.9308 - accuracy: 0.6730 - val_loss: 0.9292 - val_accuracy: 0.6875\n",
            "Q 36-80 A -44 ❌ -43\n",
            "Q 24-90 A -66 ❌ -69\n",
            "Q 16-94 A -78 ❌ -73\n",
            "Q 94-66 A 28  ❌ 29 \n",
            "Q 44-96 A -52 ✅ -52\n",
            "Q 22-88 A -66 ❌ -65\n",
            "Q 89-54 A 35  ❌ 39 \n",
            "Q 60-71 A -11 ✅ -11\n",
            "Q 81-18 A 63  ❌ 66 \n",
            "Q 26-60 A -34 ❌ -36\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 62\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 0.9270 - accuracy: 0.6769 - val_loss: 0.9307 - val_accuracy: 0.6825\n",
            "Q 42-31 A 11  ❌ 1  \n",
            "Q 36-31 A 5   ❌ 1  \n",
            "Q 67-86 A -19 ❌ -17\n",
            "Q 40-10 A 30  ❌ 20 \n",
            "Q 86-86 A 0   ❌ -  \n",
            "Q 41-37 A 4   ❌ 1  \n",
            "Q 34-46 A -12 ❌ -11\n",
            "Q 87-79 A 8   ❌ 1  \n",
            "Q 69-65 A 4   ❌ 1  \n",
            "Q 92-29 A 63  ❌ 67 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 63\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 0.9204 - accuracy: 0.6781 - val_loss: 0.9272 - val_accuracy: 0.6808\n",
            "Q 47-55 A -8  ❌ -1 \n",
            "Q 66-87 A -21 ❌ -28\n",
            "Q 93-76 A 17  ❌ 15 \n",
            "Q 58-82 A -24 ❌ -23\n",
            "Q 55-99 A -44 ❌ -43\n",
            "Q 50-33 A 17  ❌ 12 \n",
            "Q 21-66 A -45 ❌ -44\n",
            "Q 22-96 A -74 ❌ -72\n",
            "Q 45-70 A -25 ❌ -26\n",
            "Q 11-81 A -70 ❌ -76\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 64\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 0.9258 - accuracy: 0.6744 - val_loss: 0.9704 - val_accuracy: 0.6533\n",
            "Q 65-35 A 30  ❌ 34 \n",
            "Q 81-32 A 49  ❌ 56 \n",
            "Q 91-86 A 5   ❌ 1  \n",
            "Q 54-64 A -10 ❌ -1 \n",
            "Q 43-10 A 33  ❌ 31 \n",
            "Q 57-83 A -26 ❌ -23\n",
            "Q 33-48 A -15 ❌ -11\n",
            "Q 45-70 A -25 ❌ -21\n",
            "Q 14-63 A -49 ❌ -43\n",
            "Q 11-12 A -1  ❌ -3 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 65\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 0.9146 - accuracy: 0.6796 - val_loss: 0.9192 - val_accuracy: 0.6725\n",
            "Q 20-65 A -45 ❌ -44\n",
            "Q 83-64 A 19  ❌ 14 \n",
            "Q 40-52 A -12 ❌ -11\n",
            "Q 76-68 A 8   ❌ 1  \n",
            "Q 65-87 A -22 ❌ -23\n",
            "Q 87-74 A 13  ❌ 12 \n",
            "Q 31-28 A 3   ❌ 1  \n",
            "Q 53-48 A 5   ❌ 1  \n",
            "Q 88-95 A -7  ❌ -1 \n",
            "Q 58-23 A 35  ❌ 34 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 66\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 0.9082 - accuracy: 0.6832 - val_loss: 0.9154 - val_accuracy: 0.6825\n",
            "Q 16-29 A -13 ❌ -12\n",
            "Q 57-83 A -26 ❌ -23\n",
            "Q 47-81 A -34 ❌ -33\n",
            "Q 21-66 A -45 ❌ -44\n",
            "Q 30-26 A 4   ❌ 1  \n",
            "Q 34-26 A 8   ❌ 1  \n",
            "Q 79-81 A -2  ❌ -1 \n",
            "Q 13-64 A -51 ❌ -50\n",
            "Q 87-44 A 43  ❌ 49 \n",
            "Q 80-21 A 59  ❌ 66 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 67\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 0.9120 - accuracy: 0.6814 - val_loss: 0.9292 - val_accuracy: 0.6775\n",
            "Q 24-90 A -66 ❌ -60\n",
            "Q 99-81 A 18  ❌ 10 \n",
            "Q 83-64 A 19  ❌ 26 \n",
            "Q 34-44 A -10 ❌ -1 \n",
            "Q 67-59 A 8   ❌ 1  \n",
            "Q 41-37 A 4   ❌ 1  \n",
            "Q 13-30 A -17 ❌ -12\n",
            "Q 63-74 A -11 ✅ -11\n",
            "Q 41-11 A 30  ❌ 31 \n",
            "Q 31-57 A -26 ❌ -24\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 68\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 0.9089 - accuracy: 0.6777 - val_loss: 0.9099 - val_accuracy: 0.6950\n",
            "Q 44-27 A 17  ❌ 15 \n",
            "Q 26-28 A -2  ❌ -1 \n",
            "Q 65-32 A 33  ❌ 30 \n",
            "Q 47-97 A -50 ❌ -51\n",
            "Q 92-51 A 41  ❌ 49 \n",
            "Q 46-90 A -44 ❌ -43\n",
            "Q 16-70 A -54 ❌ -55\n",
            "Q 98-51 A 47  ❌ 45 \n",
            "Q 76-51 A 25  ❌ 24 \n",
            "Q 34-44 A -10 ❌ -1 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 69\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 0.8987 - accuracy: 0.6869 - val_loss: 0.9065 - val_accuracy: 0.6708\n",
            "Q 73-78 A -5  ❌ -1 \n",
            "Q 97-41 A 56  ❌ 55 \n",
            "Q 20-42 A -22 ❌ -29\n",
            "Q 13-56 A -43 ❌ -44\n",
            "Q 43-10 A 33  ❌ 31 \n",
            "Q 58-53 A 5   ❌ 1  \n",
            "Q 26-83 A -57 ❌ -55\n",
            "Q 77-39 A 38  ❌ 39 \n",
            "Q 55-70 A -15 ❌ -17\n",
            "Q 27-42 A -15 ✅ -15\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 70\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 0.8903 - accuracy: 0.6861 - val_loss: 0.9001 - val_accuracy: 0.6833\n",
            "Q 35-46 A -11 ✅ -11\n",
            "Q 86-14 A 72  ❌ 62 \n",
            "Q 71-32 A 39  ✅ 39 \n",
            "Q 11-29 A -18 ❌ -15\n",
            "Q 93-78 A 15  ✅ 15 \n",
            "Q 97-35 A 62  ❌ 67 \n",
            "Q 72-62 A 10  ❌ 1  \n",
            "Q 55-59 A -4  ❌ -1 \n",
            "Q 80-54 A 26  ❌ 22 \n",
            "Q 98-63 A 35  ❌ 39 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 71\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 0.8868 - accuracy: 0.6931 - val_loss: 0.9178 - val_accuracy: 0.6767\n",
            "Q 30-62 A -32 ❌ -39\n",
            "Q 95-27 A 68  ❌ 67 \n",
            "Q 28-39 A -11 ❌ -12\n",
            "Q 31-81 A -50 ❌ -40\n",
            "Q 71-80 A -9  ❌ -1 \n",
            "Q 79-23 A 56  ❌ 57 \n",
            "Q 16-48 A -32 ❌ -27\n",
            "Q 77-39 A 38  ❌ 39 \n",
            "Q 74-29 A 45  ❌ 47 \n",
            "Q 91-66 A 25  ✅ 25 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 72\n",
            "36/36 [==============================] - 1s 29ms/step - loss: 0.8794 - accuracy: 0.6919 - val_loss: 0.8983 - val_accuracy: 0.6792\n",
            "Q 33-56 A -23 ❌ -21\n",
            "Q 12-62 A -50 ✅ -50\n",
            "Q 44-30 A 14  ❌ 10 \n",
            "Q 71-91 A -20 ❌ -10\n",
            "Q 31-81 A -50 ✅ -50\n",
            "Q 41-60 A -19 ❌ -15\n",
            "Q 45-99 A -54 ❌ -51\n",
            "Q 17-93 A -76 ❌ -70\n",
            "Q 54-64 A -10 ❌ -1 \n",
            "Q 54-14 A 40  ❌ 30 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 73\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 0.8707 - accuracy: 0.6993 - val_loss: 0.8783 - val_accuracy: 0.6917\n",
            "Q 89-54 A 35  ❌ 39 \n",
            "Q 50-38 A 12  ✅ 12 \n",
            "Q 23-10 A 13  ❌ 10 \n",
            "Q 33-78 A -45 ❌ -44\n",
            "Q 96-57 A 39  ❌ 49 \n",
            "Q 77-29 A 48  ❌ 49 \n",
            "Q 71-17 A 54  ❌ 56 \n",
            "Q 45-19 A 26  ❌ 28 \n",
            "Q 47-84 A -37 ❌ -33\n",
            "Q 54-14 A 40  ✅ 40 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 74\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 0.8669 - accuracy: 0.6975 - val_loss: 0.8899 - val_accuracy: 0.6833\n",
            "Q 86-14 A 72  ❌ 63 \n",
            "Q 70-11 A 59  ❌ 61 \n",
            "Q 73-43 A 30  ❌ 31 \n",
            "Q 99-37 A 62  ❌ 69 \n",
            "Q 35-15 A 20  ❌ 10 \n",
            "Q 80-63 A 17  ❌ 10 \n",
            "Q 95-27 A 68  ❌ 62 \n",
            "Q 37-94 A -57 ❌ -56\n",
            "Q 94-14 A 80  ❌ 73 \n",
            "Q 41-95 A -54 ❌ -56\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 75\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 0.8621 - accuracy: 0.7009 - val_loss: 0.8731 - val_accuracy: 0.6900\n",
            "Q 94-38 A 56  ❌ 57 \n",
            "Q 29-50 A -21 ❌ -29\n",
            "Q 84-96 A -12 ✅ -12\n",
            "Q 52-83 A -31 ❌ -33\n",
            "Q 52-83 A -31 ❌ -33\n",
            "Q 72-64 A 8   ❌ 1  \n",
            "Q 83-64 A 19  ❌ 14 \n",
            "Q 32-60 A -28 ❌ -29\n",
            "Q 35-46 A -11 ✅ -11\n",
            "Q 84-76 A 8   ❌ 1  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 76\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 0.8627 - accuracy: 0.6998 - val_loss: 0.8846 - val_accuracy: 0.6850\n",
            "Q 86-86 A 0   ❌ -  \n",
            "Q 67-90 A -23 ✅ -23\n",
            "Q 43-58 A -15 ❌ -13\n",
            "Q 44-79 A -35 ❌ -36\n",
            "Q 39-96 A -57 ❌ -53\n",
            "Q 16-48 A -32 ❌ -36\n",
            "Q 81-53 A 28  ❌ 29 \n",
            "Q 58-57 A 1   ❌ -  \n",
            "Q 88-65 A 23  ❌ 29 \n",
            "Q 11-12 A -1  ❌ -  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 77\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 0.8498 - accuracy: 0.7031 - val_loss: 0.8752 - val_accuracy: 0.6850\n",
            "Q 76-16 A 60  ❌ 67 \n",
            "Q 13-56 A -43 ❌ -44\n",
            "Q 31-92 A -61 ❌ -60\n",
            "Q 76-85 A -9  ❌ -1 \n",
            "Q 29-51 A -22 ❌ -28\n",
            "Q 98-85 A 13  ❌ 10 \n",
            "Q 96-46 A 50  ❌ 47 \n",
            "Q 57-33 A 24  ❌ 23 \n",
            "Q 80-82 A -2  ❌ -  \n",
            "Q 38-21 A 17  ❌ 10 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 78\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 0.8438 - accuracy: 0.7044 - val_loss: 0.8553 - val_accuracy: 0.7025\n",
            "Q 11-24 A -13 ❌ -14\n",
            "Q 35-46 A -11 ✅ -11\n",
            "Q 81-53 A 28  ❌ 22 \n",
            "Q 63-17 A 46  ❌ 42 \n",
            "Q 39-96 A -57 ❌ -53\n",
            "Q 45-15 A 30  ❌ 32 \n",
            "Q 33-77 A -44 ✅ -44\n",
            "Q 21-63 A -42 ❌ -40\n",
            "Q 98-63 A 35  ✅ 35 \n",
            "Q 82-41 A 41  ✅ 41 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 79\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 0.8430 - accuracy: 0.7041 - val_loss: 0.8735 - val_accuracy: 0.6933\n",
            "Q 41-11 A 30  ❌ 21 \n",
            "Q 33-70 A -37 ❌ -38\n",
            "Q 14-12 A 2   ❌ 0  \n",
            "Q 71-32 A 39  ❌ 31 \n",
            "Q 12-62 A -50 ✅ -50\n",
            "Q 79-47 A 32  ❌ 22 \n",
            "Q 60-31 A 29  ❌ 21 \n",
            "Q 31-28 A 3   ❌ -  \n",
            "Q 84-56 A 28  ❌ 27 \n",
            "Q 26-98 A -72 ❌ -71\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 80\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 0.8351 - accuracy: 0.7056 - val_loss: 0.8706 - val_accuracy: 0.6942\n",
            "Q 39-96 A -57 ❌ -53\n",
            "Q 88-65 A 23  ❌ 29 \n",
            "Q 31-57 A -26 ✅ -26\n",
            "Q 79-81 A -2  ❌ -  \n",
            "Q 53-63 A -10 ❌ -1 \n",
            "Q 53-22 A 31  ✅ 31 \n",
            "Q 53-22 A 31  ✅ 31 \n",
            "Q 14-71 A -57 ❌ -58\n",
            "Q 38-27 A 11  ✅ 11 \n",
            "Q 94-60 A 34  ❌ 39 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 81\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 0.8587 - accuracy: 0.6959 - val_loss: 0.8427 - val_accuracy: 0.7067\n",
            "Q 63-23 A 40  ❌ 41 \n",
            "Q 14-75 A -61 ❌ -62\n",
            "Q 80-39 A 41  ❌ 46 \n",
            "Q 98-85 A 13  ❌ 10 \n",
            "Q 33-48 A -15 ✅ -15\n",
            "Q 26-79 A -53 ❌ -51\n",
            "Q 44-79 A -35 ❌ -33\n",
            "Q 74-51 A 23  ❌ 24 \n",
            "Q 33-77 A -44 ✅ -44\n",
            "Q 11-12 A -1  ❌ -  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 82\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 0.8258 - accuracy: 0.7132 - val_loss: 0.8370 - val_accuracy: 0.7050\n",
            "Q 44-96 A -52 ✅ -52\n",
            "Q 80-82 A -2  ❌ -1 \n",
            "Q 33-78 A -45 ❌ -44\n",
            "Q 11-11 A 0   ❌ -  \n",
            "Q 24-90 A -66 ❌ -60\n",
            "Q 34-46 A -12 ❌ -11\n",
            "Q 94-14 A 80  ❌ 70 \n",
            "Q 53-63 A -10 ✅ -10\n",
            "Q 22-96 A -74 ❌ -75\n",
            "Q 81-32 A 49  ❌ 40 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 83\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 0.8200 - accuracy: 0.7136 - val_loss: 0.8455 - val_accuracy: 0.7050\n",
            "Q 30-87 A -57 ❌ -55\n",
            "Q 65-64 A 1   ✅ 1  \n",
            "Q 63-23 A 40  ❌ 41 \n",
            "Q 92-29 A 63  ❌ 66 \n",
            "Q 26-17 A 9   ❌ 11 \n",
            "Q 58-82 A -24 ❌ -28\n",
            "Q 64-61 A 3   ❌ 1  \n",
            "Q 61-45 A 16  ❌ 15 \n",
            "Q 11-11 A 0   ❌ -  \n",
            "Q 63-23 A 40  ❌ 41 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 84\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 0.8109 - accuracy: 0.7189 - val_loss: 0.8290 - val_accuracy: 0.6958\n",
            "Q 39-46 A -7  ❌ -1 \n",
            "Q 42-93 A -51 ❌ -50\n",
            "Q 12-48 A -36 ❌ -37\n",
            "Q 53-22 A 31  ✅ 31 \n",
            "Q 31-73 A -42 ✅ -42\n",
            "Q 59-14 A 45  ❌ 44 \n",
            "Q 11-29 A -18 ❌ -15\n",
            "Q 32-60 A -28 ❌ -29\n",
            "Q 34-25 A 9   ❌ 1  \n",
            "Q 72-64 A 8   ❌ 1  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 85\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 0.8072 - accuracy: 0.7190 - val_loss: 0.8525 - val_accuracy: 0.6875\n",
            "Q 57-55 A 2   ❌ 1  \n",
            "Q 15-51 A -36 ❌ -34\n",
            "Q 49-79 A -30 ❌ -26\n",
            "Q 67-90 A -23 ✅ -23\n",
            "Q 46-15 A 31  ❌ 34 \n",
            "Q 97-35 A 62  ✅ 62 \n",
            "Q 43-98 A -55 ❌ -54\n",
            "Q 75-80 A -5  ❌ -1 \n",
            "Q 12-62 A -50 ✅ -50\n",
            "Q 86-99 A -13 ❌ -11\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 86\n",
            "36/36 [==============================] - 1s 29ms/step - loss: 0.8050 - accuracy: 0.7188 - val_loss: 0.8166 - val_accuracy: 0.7092\n",
            "Q 48-99 A -51 ❌ -50\n",
            "Q 43-23 A 20  ❌ 10 \n",
            "Q 54-54 A 0   ❌ -  \n",
            "Q 13-30 A -17 ❌ -15\n",
            "Q 77-12 A 65  ✅ 65 \n",
            "Q 16-48 A -32 ❌ -35\n",
            "Q 33-82 A -49 ❌ -50\n",
            "Q 73-32 A 41  ✅ 41 \n",
            "Q 86-99 A -13 ❌ -10\n",
            "Q 24-32 A -8  ❌ -1 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 87\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 0.7918 - accuracy: 0.7253 - val_loss: 0.8085 - val_accuracy: 0.7142\n",
            "Q 49-79 A -30 ❌ -38\n",
            "Q 11-24 A -13 ❌ -12\n",
            "Q 70-11 A 59  ❌ 68 \n",
            "Q 72-18 A 54  ❌ 56 \n",
            "Q 53-63 A -10 ❌ -1 \n",
            "Q 52-83 A -31 ❌ -32\n",
            "Q 12-48 A -36 ❌ -37\n",
            "Q 96-46 A 50  ❌ 40 \n",
            "Q 52-85 A -33 ❌ -32\n",
            "Q 46-62 A -16 ❌ -11\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 88\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 0.7919 - accuracy: 0.7243 - val_loss: 0.8082 - val_accuracy: 0.7000\n",
            "Q 99-31 A 68  ❌ 75 \n",
            "Q 35-91 A -56 ✅ -56\n",
            "Q 60-34 A 26  ❌ 28 \n",
            "Q 43-23 A 20  ❌ 10 \n",
            "Q 37-63 A -26 ❌ -28\n",
            "Q 24-32 A -8  ❌ -1 \n",
            "Q 71-80 A -9  ❌ -1 \n",
            "Q 42-83 A -41 ❌ -42\n",
            "Q 60-34 A 26  ❌ 28 \n",
            "Q 24-90 A -66 ❌ -60\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 89\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 0.7794 - accuracy: 0.7249 - val_loss: 0.8032 - val_accuracy: 0.7008\n",
            "Q 99-17 A 82  ❌ 81 \n",
            "Q 19-62 A -43 ✅ -43\n",
            "Q 39-55 A -16 ❌ -15\n",
            "Q 50-47 A 3   ❌ -  \n",
            "Q 19-37 A -18 ❌ -15\n",
            "Q 91-66 A 25  ✅ 25 \n",
            "Q 48-59 A -11 ✅ -11\n",
            "Q 31-57 A -26 ✅ -26\n",
            "Q 43-10 A 33  ❌ 31 \n",
            "Q 99-81 A 18  ❌ 15 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 90\n",
            "36/36 [==============================] - 1s 26ms/step - loss: 0.7704 - accuracy: 0.7279 - val_loss: 0.8011 - val_accuracy: 0.7025\n",
            "Q 61-77 A -16 ❌ -15\n",
            "Q 41-60 A -19 ❌ -29\n",
            "Q 87-61 A 26  ❌ 25 \n",
            "Q 44-75 A -31 ✅ -31\n",
            "Q 40-10 A 30  ❌ 39 \n",
            "Q 79-23 A 56  ❌ 55 \n",
            "Q 14-71 A -57 ❌ -50\n",
            "Q 81-53 A 28  ❌ 29 \n",
            "Q 59-14 A 45  ❌ 44 \n",
            "Q 48-69 A -21 ✅ -21\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 91\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 0.7578 - accuracy: 0.7385 - val_loss: 0.7783 - val_accuracy: 0.7125\n",
            "Q 40-68 A -28 ❌ -26\n",
            "Q 14-70 A -56 ❌ -50\n",
            "Q 84-56 A 28  ❌ 22 \n",
            "Q 68-14 A 54  ❌ 56 \n",
            "Q 44-90 A -46 ❌ -43\n",
            "Q 53-70 A -17 ❌ -16\n",
            "Q 38-80 A -42 ❌ -43\n",
            "Q 98-85 A 13  ❌ 12 \n",
            "Q 35-89 A -54 ❌ -51\n",
            "Q 81-97 A -16 ❌ -14\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 92\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 0.7475 - accuracy: 0.7415 - val_loss: 0.7679 - val_accuracy: 0.7167\n",
            "Q 28-33 A -5  ❌ -1 \n",
            "Q 71-32 A 39  ❌ 30 \n",
            "Q 11-24 A -13 ❌ -12\n",
            "Q 64-82 A -18 ✅ -18\n",
            "Q 13-72 A -59 ❌ -60\n",
            "Q 76-68 A 8   ❌ 1  \n",
            "Q 41-37 A 4   ❌ 1  \n",
            "Q 92-32 A 60  ✅ 60 \n",
            "Q 62-50 A 12  ❌ 10 \n",
            "Q 86-99 A -13 ❌ -11\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 93\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 0.7418 - accuracy: 0.7411 - val_loss: 0.7583 - val_accuracy: 0.7192\n",
            "Q 32-20 A 12  ❌ 10 \n",
            "Q 20-42 A -22 ❌ -29\n",
            "Q 15-70 A -55 ❌ -58\n",
            "Q 62-38 A 24  ❌ 26 \n",
            "Q 14-12 A 2   ❌ 0  \n",
            "Q 80-45 A 35  ❌ 36 \n",
            "Q 52-60 A -8  ❌ -1 \n",
            "Q 72-18 A 54  ❌ 56 \n",
            "Q 39-55 A -16 ❌ -17\n",
            "Q 42-46 A -4  ✅ -4 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 94\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 0.7436 - accuracy: 0.7387 - val_loss: 0.7508 - val_accuracy: 0.7150\n",
            "Q 14-12 A 2   ❌ 0  \n",
            "Q 55-11 A 44  ❌ 43 \n",
            "Q 16-44 A -28 ❌ -27\n",
            "Q 66-33 A 33  ❌ 34 \n",
            "Q 91-54 A 37  ❌ 36 \n",
            "Q 76-85 A -9  ❌ -1 \n",
            "Q 41-68 A -27 ❌ -26\n",
            "Q 73-32 A 41  ❌ 40 \n",
            "Q 58-82 A -24 ❌ -26\n",
            "Q 31-57 A -26 ❌ -27\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 95\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 0.7424 - accuracy: 0.7373 - val_loss: 0.7709 - val_accuracy: 0.7058\n",
            "Q 14-75 A -61 ❌ -50\n",
            "Q 93-60 A 33  ❌ 39 \n",
            "Q 21-66 A -45 ❌ -44\n",
            "Q 73-51 A 22  ❌ 23 \n",
            "Q 94-38 A 56  ✅ 56 \n",
            "Q 58-23 A 35  ❌ 34 \n",
            "Q 84-56 A 28  ❌ 29 \n",
            "Q 16-94 A -78 ❌ -70\n",
            "Q 15-63 A -48 ❌ -49\n",
            "Q 34-25 A 9   ❌ 1  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 96\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 0.7295 - accuracy: 0.7440 - val_loss: 0.7319 - val_accuracy: 0.7275\n",
            "Q 53-22 A 31  ✅ 31 \n",
            "Q 89-25 A 64  ❌ 61 \n",
            "Q 14-66 A -52 ✅ -52\n",
            "Q 97-60 A 37  ✅ 37 \n",
            "Q 34-24 A 10  ❌ 1  \n",
            "Q 64-82 A -18 ✅ -18\n",
            "Q 24-33 A -9  ❌ -1 \n",
            "Q 76-85 A -9  ❌ -10\n",
            "Q 65-53 A 12  ✅ 12 \n",
            "Q 55-99 A -44 ❌ -43\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 97\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 0.7013 - accuracy: 0.7589 - val_loss: 0.7116 - val_accuracy: 0.7425\n",
            "Q 21-30 A -9  ❌ -1 \n",
            "Q 97-35 A 62  ❌ 61 \n",
            "Q 33-70 A -37 ❌ -38\n",
            "Q 90-41 A 49  ❌ 59 \n",
            "Q 80-54 A 26  ❌ 22 \n",
            "Q 44-79 A -35 ❌ -32\n",
            "Q 69-83 A -14 ❌ -15\n",
            "Q 84-96 A -12 ❌ -13\n",
            "Q 36-28 A 8   ❌ 1  \n",
            "Q 61-77 A -16 ❌ -17\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 98\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 0.6947 - accuracy: 0.7601 - val_loss: 0.6957 - val_accuracy: 0.7483\n",
            "Q 27-13 A 14  ❌ 13 \n",
            "Q 32-61 A -29 ✅ -29\n",
            "Q 97-35 A 62  ❌ 61 \n",
            "Q 26-60 A -34 ❌ -35\n",
            "Q 47-81 A -34 ❌ -35\n",
            "Q 66-87 A -21 ✅ -21\n",
            "Q 44-79 A -35 ❌ -33\n",
            "Q 52-47 A 5   ❌ 1  \n",
            "Q 53-63 A -10 ✅ -10\n",
            "Q 65-53 A 12  ❌ 13 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 99\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 0.6848 - accuracy: 0.7634 - val_loss: 0.6806 - val_accuracy: 0.7400\n",
            "Q 11-19 A -8  ❌ -5 \n",
            "Q 37-63 A -26 ❌ -28\n",
            "Q 71-42 A 29  ❌ 20 \n",
            "Q 87-79 A 8   ❌ 1  \n",
            "Q 15-85 A -70 ❌ -71\n",
            "Q 59-50 A 9   ❌ 1  \n",
            "Q 63-23 A 40  ❌ 30 \n",
            "Q 67-90 A -23 ✅ -23\n",
            "Q 14-31 A -17 ❌ -18\n",
            "Q 71-34 A 37  ❌ 38 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 100\n",
            "36/36 [==============================] - 1s 29ms/step - loss: 0.6698 - accuracy: 0.7679 - val_loss: 0.6555 - val_accuracy: 0.7642\n",
            "Q 41-37 A 4   ❌ 1  \n",
            "Q 30-87 A -57 ✅ -57\n",
            "Q 58-57 A 1   ❌ 0  \n",
            "Q 48-99 A -51 ❌ -50\n",
            "Q 62-42 A 20  ✅ 20 \n",
            "Q 93-76 A 17  ❌ 16 \n",
            "Q 57-33 A 24  ✅ 24 \n",
            "Q 44-96 A -52 ✅ -52\n",
            "Q 41-37 A 4   ❌ 1  \n",
            "Q 49-79 A -30 ✅ -30\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 101\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 0.6566 - accuracy: 0.7726 - val_loss: 0.6479 - val_accuracy: 0.7633\n",
            "Q 14-31 A -17 ✅ -17\n",
            "Q 43-58 A -15 ❌ -16\n",
            "Q 89-91 A -2  ❌ -  \n",
            "Q 36-33 A 3   ❌ 1  \n",
            "Q 50-47 A 3   ❌ -  \n",
            "Q 83-85 A -2  ✅ -2 \n",
            "Q 89-54 A 35  ✅ 35 \n",
            "Q 14-63 A -49 ❌ -40\n",
            "Q 30-26 A 4   ❌ 1  \n",
            "Q 89-25 A 64  ❌ 62 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 102\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 0.6434 - accuracy: 0.7773 - val_loss: 0.6505 - val_accuracy: 0.7542\n",
            "Q 26-79 A -53 ❌ -52\n",
            "Q 37-85 A -48 ❌ -40\n",
            "Q 39-73 A -34 ❌ -35\n",
            "Q 53-69 A -16 ✅ -16\n",
            "Q 58-82 A -24 ❌ -25\n",
            "Q 84-96 A -12 ❌ -13\n",
            "Q 78-72 A 6   ❌ 1  \n",
            "Q 31-23 A 8   ❌ 1  \n",
            "Q 96-46 A 50  ❌ 41 \n",
            "Q 42-83 A -41 ❌ -40\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 103\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 0.6243 - accuracy: 0.7876 - val_loss: 0.6167 - val_accuracy: 0.7683\n",
            "Q 92-51 A 41  ❌ 49 \n",
            "Q 52-83 A -31 ✅ -31\n",
            "Q 30-71 A -41 ❌ -40\n",
            "Q 96-78 A 18  ❌ 19 \n",
            "Q 97-15 A 82  ❌ 81 \n",
            "Q 33-42 A -9  ✅ -9 \n",
            "Q 80-54 A 26  ❌ 27 \n",
            "Q 42-83 A -41 ❌ -40\n",
            "Q 76-16 A 60  ❌ 61 \n",
            "Q 63-74 A -11 ✅ -11\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 104\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 0.6062 - accuracy: 0.7928 - val_loss: 0.6279 - val_accuracy: 0.7800\n",
            "Q 40-11 A 29  ✅ 29 \n",
            "Q 62-38 A 24  ❌ 26 \n",
            "Q 82-69 A 13  ✅ 13 \n",
            "Q 31-17 A 14  ❌ 13 \n",
            "Q 60-51 A 9   ❌ 1  \n",
            "Q 76-57 A 19  ✅ 19 \n",
            "Q 34-26 A 8   ❌ 1  \n",
            "Q 80-82 A -2  ❌ -1 \n",
            "Q 41-11 A 30  ❌ 21 \n",
            "Q 24-90 A -66 ✅ -66\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 105\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 0.5950 - accuracy: 0.7994 - val_loss: 0.5755 - val_accuracy: 0.7958\n",
            "Q 11-12 A -1  ❌ -  \n",
            "Q 61-29 A 32  ❌ 35 \n",
            "Q 21-46 A -25 ✅ -25\n",
            "Q 99-39 A 60  ❌ 59 \n",
            "Q 76-68 A 8   ❌ 1  \n",
            "Q 32-60 A -28 ✅ -28\n",
            "Q 52-13 A 39  ❌ 30 \n",
            "Q 53-63 A -10 ✅ -10\n",
            "Q 21-66 A -45 ✅ -45\n",
            "Q 14-75 A -61 ✅ -61\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 106\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 0.5718 - accuracy: 0.8112 - val_loss: 0.5590 - val_accuracy: 0.8033\n",
            "Q 28-48 A -20 ❌ -19\n",
            "Q 13-30 A -17 ✅ -17\n",
            "Q 16-29 A -13 ❌ -12\n",
            "Q 45-99 A -54 ❌ -53\n",
            "Q 79-23 A 56  ✅ 56 \n",
            "Q 34-26 A 8   ❌ 1  \n",
            "Q 85-67 A 18  ✅ 18 \n",
            "Q 41-11 A 30  ❌ 21 \n",
            "Q 88-95 A -7  ❌ -2 \n",
            "Q 43-98 A -55 ❌ -56\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 107\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 0.5578 - accuracy: 0.8196 - val_loss: 0.5312 - val_accuracy: 0.8208\n",
            "Q 65-80 A -15 ❌ -16\n",
            "Q 39-73 A -34 ❌ -35\n",
            "Q 78-72 A 6   ❌ 1  \n",
            "Q 65-17 A 48  ✅ 48 \n",
            "Q 41-37 A 4   ❌ 1  \n",
            "Q 15-63 A -48 ✅ -48\n",
            "Q 22-88 A -66 ✅ -66\n",
            "Q 67-66 A 1   ❌ 0  \n",
            "Q 33-77 A -44 ✅ -44\n",
            "Q 58-82 A -24 ✅ -24\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 108\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 0.5507 - accuracy: 0.8181 - val_loss: 0.5267 - val_accuracy: 0.8250\n",
            "Q 77-41 A 36  ❌ 35 \n",
            "Q 32-23 A 9   ❌ 1  \n",
            "Q 14-63 A -49 ❌ -40\n",
            "Q 70-77 A -7  ❌ -6 \n",
            "Q 26-28 A -2  ❌ -1 \n",
            "Q 79-81 A -2  ❌ -4 \n",
            "Q 33-77 A -44 ✅ -44\n",
            "Q 43-10 A 33  ✅ 33 \n",
            "Q 15-51 A -36 ❌ -35\n",
            "Q 65-17 A 48  ✅ 48 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 109\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 0.5335 - accuracy: 0.8250 - val_loss: 0.5074 - val_accuracy: 0.8242\n",
            "Q 71-42 A 29  ❌ 20 \n",
            "Q 31-83 A -52 ✅ -52\n",
            "Q 11-81 A -70 ✅ -70\n",
            "Q 99-17 A 82  ❌ 81 \n",
            "Q 30-71 A -41 ✅ -41\n",
            "Q 65-65 A 0   ❌ -  \n",
            "Q 31-28 A 3   ❌ -  \n",
            "Q 72-62 A 10  ✅ 10 \n",
            "Q 99-37 A 62  ❌ 61 \n",
            "Q 84-76 A 8   ❌ 1  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 110\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 0.5110 - accuracy: 0.8419 - val_loss: 0.4965 - val_accuracy: 0.8367\n",
            "Q 98-85 A 13  ❌ 12 \n",
            "Q 83-67 A 16  ✅ 16 \n",
            "Q 45-99 A -54 ❌ -53\n",
            "Q 45-99 A -54 ❌ -53\n",
            "Q 89-25 A 64  ❌ 65 \n",
            "Q 46-15 A 31  ✅ 31 \n",
            "Q 31-83 A -52 ✅ -52\n",
            "Q 93-78 A 15  ✅ 15 \n",
            "Q 72-14 A 58  ✅ 58 \n",
            "Q 66-56 A 10  ✅ 10 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 111\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 0.4981 - accuracy: 0.8423 - val_loss: 0.4952 - val_accuracy: 0.8283\n",
            "Q 11-12 A -1  ✅ -1 \n",
            "Q 70-11 A 59  ❌ 69 \n",
            "Q 93-60 A 33  ❌ 32 \n",
            "Q 54-64 A -10 ✅ -10\n",
            "Q 77-39 A 38  ✅ 38 \n",
            "Q 89-54 A 35  ✅ 35 \n",
            "Q 70-11 A 59  ❌ 69 \n",
            "Q 47-84 A -37 ✅ -37\n",
            "Q 74-29 A 45  ❌ 46 \n",
            "Q 69-41 A 28  ❌ 26 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 112\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 0.4823 - accuracy: 0.8538 - val_loss: 0.4679 - val_accuracy: 0.8642\n",
            "Q 75-16 A 59  ❌ 69 \n",
            "Q 64-61 A 3   ❌ 1  \n",
            "Q 41-96 A -55 ✅ -55\n",
            "Q 83-64 A 19  ✅ 19 \n",
            "Q 73-43 A 30  ✅ 30 \n",
            "Q 11-24 A -13 ✅ -13\n",
            "Q 15-63 A -48 ✅ -48\n",
            "Q 14-70 A -56 ✅ -56\n",
            "Q 93-34 A 59  ❌ 50 \n",
            "Q 60-31 A 29  ✅ 29 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 113\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 0.4732 - accuracy: 0.8573 - val_loss: 0.4771 - val_accuracy: 0.8608\n",
            "Q 67-59 A 8   ❌ 1  \n",
            "Q 71-17 A 54  ✅ 54 \n",
            "Q 47-60 A -13 ❌ -15\n",
            "Q 52-79 A -27 ❌ -26\n",
            "Q 29-50 A -21 ❌ -23\n",
            "Q 26-74 A -48 ✅ -48\n",
            "Q 24-33 A -9  ✅ -9 \n",
            "Q 14-12 A 2   ❌ 1  \n",
            "Q 47-60 A -13 ❌ -15\n",
            "Q 16-94 A -78 ✅ -78\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 114\n",
            "36/36 [==============================] - 1s 30ms/step - loss: 0.4578 - accuracy: 0.8645 - val_loss: 0.4506 - val_accuracy: 0.8675\n",
            "Q 42-93 A -51 ❌ -50\n",
            "Q 94-66 A 28  ✅ 28 \n",
            "Q 89-59 A 30  ❌ 20 \n",
            "Q 47-84 A -37 ✅ -37\n",
            "Q 26-79 A -53 ✅ -53\n",
            "Q 97-15 A 82  ✅ 82 \n",
            "Q 32-23 A 9   ❌ 1  \n",
            "Q 60-71 A -11 ✅ -11\n",
            "Q 34-24 A 10  ✅ 10 \n",
            "Q 37-85 A -48 ✅ -48\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 115\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 0.4460 - accuracy: 0.8691 - val_loss: 0.4489 - val_accuracy: 0.8567\n",
            "Q 88-65 A 23  ❌ 22 \n",
            "Q 36-28 A 8   ❌ 1  \n",
            "Q 28-48 A -20 ✅ -20\n",
            "Q 14-71 A -57 ✅ -57\n",
            "Q 48-59 A -11 ✅ -11\n",
            "Q 28-48 A -20 ✅ -20\n",
            "Q 30-34 A -4  ✅ -4 \n",
            "Q 63-26 A 37  ✅ 37 \n",
            "Q 41-96 A -55 ✅ -55\n",
            "Q 83-85 A -2  ✅ -2 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 116\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 0.4302 - accuracy: 0.8783 - val_loss: 0.4278 - val_accuracy: 0.8708\n",
            "Q 24-90 A -66 ✅ -66\n",
            "Q 27-42 A -15 ✅ -15\n",
            "Q 28-33 A -5  ✅ -5 \n",
            "Q 58-53 A 5   ✅ 5  \n",
            "Q 31-81 A -50 ✅ -50\n",
            "Q 42-78 A -36 ✅ -36\n",
            "Q 34-25 A 9   ❌ 1  \n",
            "Q 15-63 A -48 ✅ -48\n",
            "Q 87-74 A 13  ❌ 14 \n",
            "Q 21-30 A -9  ❌ -1 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 117\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 0.4216 - accuracy: 0.8850 - val_loss: 0.4171 - val_accuracy: 0.8775\n",
            "Q 52-60 A -8  ✅ -8 \n",
            "Q 67-66 A 1   ❌ -  \n",
            "Q 62-37 A 25  ❌ 26 \n",
            "Q 63-23 A 40  ✅ 40 \n",
            "Q 66-56 A 10  ✅ 10 \n",
            "Q 21-66 A -45 ✅ -45\n",
            "Q 43-98 A -55 ✅ -55\n",
            "Q 49-21 A 28  ❌ 27 \n",
            "Q 72-14 A 58  ✅ 58 \n",
            "Q 14-34 A -20 ✅ -20\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 118\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 0.4118 - accuracy: 0.8871 - val_loss: 0.4143 - val_accuracy: 0.8758\n",
            "Q 31-15 A 16  ✅ 16 \n",
            "Q 89-54 A 35  ❌ 45 \n",
            "Q 43-98 A -55 ✅ -55\n",
            "Q 72-18 A 54  ❌ 55 \n",
            "Q 42-46 A -4  ✅ -4 \n",
            "Q 11-81 A -70 ✅ -70\n",
            "Q 57-55 A 2   ❌ 1  \n",
            "Q 85-47 A 38  ✅ 38 \n",
            "Q 41-60 A -19 ✅ -19\n",
            "Q 80-39 A 41  ❌ 42 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 119\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 0.4040 - accuracy: 0.8891 - val_loss: 0.4113 - val_accuracy: 0.8842\n",
            "Q 82-69 A 13  ✅ 13 \n",
            "Q 85-47 A 38  ✅ 38 \n",
            "Q 15-70 A -55 ✅ -55\n",
            "Q 86-54 A 32  ✅ 32 \n",
            "Q 61-45 A 16  ✅ 16 \n",
            "Q 69-83 A -14 ✅ -14\n",
            "Q 26-17 A 9   ❌ 1  \n",
            "Q 11-11 A 0   ❌ -  \n",
            "Q 96-78 A 18  ✅ 18 \n",
            "Q 67-66 A 1   ❌ -  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 120\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 0.3940 - accuracy: 0.8934 - val_loss: 0.3806 - val_accuracy: 0.9042\n",
            "Q 47-97 A -50 ✅ -50\n",
            "Q 55-59 A -4  ✅ -4 \n",
            "Q 58-82 A -24 ✅ -24\n",
            "Q 67-43 A 24  ✅ 24 \n",
            "Q 37-63 A -26 ✅ -26\n",
            "Q 65-80 A -15 ❌ -16\n",
            "Q 19-62 A -43 ✅ -43\n",
            "Q 62-48 A 14  ❌ 15 \n",
            "Q 85-64 A 21  ✅ 21 \n",
            "Q 62-95 A -33 ✅ -33\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 121\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 0.3765 - accuracy: 0.9032 - val_loss: 0.3716 - val_accuracy: 0.9075\n",
            "Q 68-14 A 54  ❌ 55 \n",
            "Q 39-73 A -34 ✅ -34\n",
            "Q 15-13 A 2   ❌ 3  \n",
            "Q 57-83 A -26 ✅ -26\n",
            "Q 55-11 A 44  ✅ 44 \n",
            "Q 14-92 A -78 ✅ -78\n",
            "Q 47-81 A -34 ❌ -35\n",
            "Q 33-70 A -37 ✅ -37\n",
            "Q 33-56 A -23 ❌ -24\n",
            "Q 14-31 A -17 ❌ -18\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 122\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 0.3685 - accuracy: 0.9092 - val_loss: 0.3606 - val_accuracy: 0.8958\n",
            "Q 26-74 A -48 ✅ -48\n",
            "Q 86-11 A 75  ✅ 75 \n",
            "Q 81-74 A 7   ✅ 7  \n",
            "Q 76-57 A 19  ✅ 19 \n",
            "Q 64-12 A 52  ✅ 52 \n",
            "Q 11-29 A -18 ❌ -17\n",
            "Q 61-77 A -16 ❌ -15\n",
            "Q 42-93 A -51 ✅ -51\n",
            "Q 28-39 A -11 ✅ -11\n",
            "Q 61-77 A -16 ❌ -15\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 123\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 0.3532 - accuracy: 0.9147 - val_loss: 0.3585 - val_accuracy: 0.9058\n",
            "Q 62-88 A -26 ✅ -26\n",
            "Q 15-63 A -48 ✅ -48\n",
            "Q 21-63 A -42 ✅ -42\n",
            "Q 72-62 A 10  ✅ 10 \n",
            "Q 54-97 A -43 ✅ -43\n",
            "Q 34-19 A 15  ❌ 16 \n",
            "Q 40-10 A 30  ✅ 30 \n",
            "Q 14-34 A -20 ✅ -20\n",
            "Q 80-54 A 26  ✅ 26 \n",
            "Q 45-15 A 30  ✅ 30 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 124\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 0.3493 - accuracy: 0.9137 - val_loss: 0.3526 - val_accuracy: 0.9108\n",
            "Q 80-54 A 26  ✅ 26 \n",
            "Q 92-32 A 60  ✅ 60 \n",
            "Q 67-90 A -23 ❌ -22\n",
            "Q 62-48 A 14  ❌ 15 \n",
            "Q 13-56 A -43 ✅ -43\n",
            "Q 86-54 A 32  ✅ 32 \n",
            "Q 64-12 A 52  ✅ 52 \n",
            "Q 47-57 A -10 ✅ -10\n",
            "Q 31-73 A -42 ✅ -42\n",
            "Q 28-95 A -67 ✅ -67\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 125\n",
            "36/36 [==============================] - 1s 27ms/step - loss: 0.3367 - accuracy: 0.9195 - val_loss: 0.3356 - val_accuracy: 0.9167\n",
            "Q 55-99 A -44 ✅ -44\n",
            "Q 28-95 A -67 ✅ -67\n",
            "Q 50-34 A 16  ✅ 16 \n",
            "Q 83-64 A 19  ✅ 19 \n",
            "Q 93-76 A 17  ✅ 17 \n",
            "Q 28-52 A -24 ✅ -24\n",
            "Q 30-71 A -41 ✅ -41\n",
            "Q 93-34 A 59  ✅ 59 \n",
            "Q 85-64 A 21  ✅ 21 \n",
            "Q 80-82 A -2  ✅ -2 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 126\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 0.3315 - accuracy: 0.9219 - val_loss: 0.3764 - val_accuracy: 0.8717\n",
            "Q 15-13 A 2   ❌ 3  \n",
            "Q 53-70 A -17 ✅ -17\n",
            "Q 32-61 A -29 ✅ -29\n",
            "Q 14-70 A -56 ✅ -56\n",
            "Q 29-50 A -21 ❌ -22\n",
            "Q 42-46 A -4  ✅ -4 \n",
            "Q 67-59 A 8   ✅ 8  \n",
            "Q 69-91 A -22 ❌ -23\n",
            "Q 34-26 A 8   ✅ 8  \n",
            "Q 46-40 A 6   ❌ 7  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 127\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 0.3293 - accuracy: 0.9221 - val_loss: 0.3295 - val_accuracy: 0.9100\n",
            "Q 39-96 A -57 ✅ -57\n",
            "Q 99-37 A 62  ✅ 62 \n",
            "Q 31-73 A -42 ✅ -42\n",
            "Q 50-33 A 17  ✅ 17 \n",
            "Q 99-31 A 68  ❌ 67 \n",
            "Q 93-60 A 33  ✅ 33 \n",
            "Q 48-99 A -51 ✅ -51\n",
            "Q 37-94 A -57 ✅ -57\n",
            "Q 44-96 A -52 ✅ -52\n",
            "Q 53-22 A 31  ✅ 31 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 128\n",
            "36/36 [==============================] - 1s 31ms/step - loss: 0.3117 - accuracy: 0.9306 - val_loss: 0.3169 - val_accuracy: 0.9217\n",
            "Q 26-17 A 9   ❌ 10 \n",
            "Q 47-84 A -37 ✅ -37\n",
            "Q 30-87 A -57 ✅ -57\n",
            "Q 11-81 A -70 ✅ -70\n",
            "Q 81-97 A -16 ✅ -16\n",
            "Q 83-85 A -2  ✅ -2 \n",
            "Q 31-28 A 3   ❌ 4  \n",
            "Q 61-77 A -16 ✅ -16\n",
            "Q 73-43 A 30  ✅ 30 \n",
            "Q 47-97 A -50 ✅ -50\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 129\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 0.3023 - accuracy: 0.9362 - val_loss: 0.3160 - val_accuracy: 0.9200\n",
            "Q 86-99 A -13 ✅ -13\n",
            "Q 73-78 A -5  ✅ -5 \n",
            "Q 93-34 A 59  ✅ 59 \n",
            "Q 31-57 A -26 ✅ -26\n",
            "Q 38-80 A -42 ✅ -42\n",
            "Q 89-59 A 30  ❌ 20 \n",
            "Q 47-84 A -37 ✅ -37\n",
            "Q 47-81 A -34 ✅ -34\n",
            "Q 24-90 A -66 ✅ -66\n",
            "Q 74-51 A 23  ✅ 23 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 130\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 0.2958 - accuracy: 0.9403 - val_loss: 0.2968 - val_accuracy: 0.9308\n",
            "Q 11-12 A -1  ✅ -1 \n",
            "Q 52-11 A 41  ✅ 41 \n",
            "Q 52-78 A -26 ✅ -26\n",
            "Q 67-59 A 8   ❌ 9  \n",
            "Q 78-72 A 6   ❌ 7  \n",
            "Q 13-56 A -43 ✅ -43\n",
            "Q 60-51 A 9   ❌ 8  \n",
            "Q 53-70 A -17 ✅ -17\n",
            "Q 82-69 A 13  ✅ 13 \n",
            "Q 32-60 A -28 ✅ -28\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 131\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 0.2894 - accuracy: 0.9402 - val_loss: 0.3022 - val_accuracy: 0.9233\n",
            "Q 48-59 A -11 ✅ -11\n",
            "Q 49-21 A 28  ✅ 28 \n",
            "Q 34-46 A -12 ✅ -12\n",
            "Q 47-57 A -10 ✅ -10\n",
            "Q 82-41 A 41  ✅ 41 \n",
            "Q 80-45 A 35  ✅ 35 \n",
            "Q 39-73 A -34 ✅ -34\n",
            "Q 31-47 A -16 ✅ -16\n",
            "Q 45-64 A -19 ✅ -19\n",
            "Q 57-33 A 24  ✅ 24 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 132\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 0.2849 - accuracy: 0.9409 - val_loss: 0.2901 - val_accuracy: 0.9292\n",
            "Q 47-57 A -10 ✅ -10\n",
            "Q 92-29 A 63  ❌ 62 \n",
            "Q 90-19 A 71  ❌ 62 \n",
            "Q 14-70 A -56 ✅ -56\n",
            "Q 87-44 A 43  ✅ 43 \n",
            "Q 34-26 A 8   ❌ 1  \n",
            "Q 93-60 A 33  ✅ 33 \n",
            "Q 53-73 A -20 ✅ -20\n",
            "Q 37-94 A -57 ✅ -57\n",
            "Q 26-68 A -42 ✅ -42\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 133\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 0.2764 - accuracy: 0.9426 - val_loss: 0.2922 - val_accuracy: 0.9267\n",
            "Q 79-81 A -2  ✅ -2 \n",
            "Q 34-57 A -23 ✅ -23\n",
            "Q 79-47 A 32  ✅ 32 \n",
            "Q 40-68 A -28 ❌ -27\n",
            "Q 64-82 A -18 ✅ -18\n",
            "Q 42-46 A -4  ✅ -4 \n",
            "Q 98-94 A 4   ❌ 3  \n",
            "Q 59-14 A 45  ✅ 45 \n",
            "Q 39-46 A -7  ✅ -7 \n",
            "Q 61-77 A -16 ✅ -16\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 134\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 0.2679 - accuracy: 0.9474 - val_loss: 0.2849 - val_accuracy: 0.9350\n",
            "Q 87-61 A 26  ✅ 26 \n",
            "Q 15-13 A 2   ❌ 3  \n",
            "Q 24-90 A -66 ✅ -66\n",
            "Q 16-48 A -32 ✅ -32\n",
            "Q 98-63 A 35  ✅ 35 \n",
            "Q 81-97 A -16 ✅ -16\n",
            "Q 58-57 A 1   ❌ 0  \n",
            "Q 41-73 A -32 ✅ -32\n",
            "Q 49-21 A 28  ✅ 28 \n",
            "Q 76-16 A 60  ✅ 60 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 135\n",
            "36/36 [==============================] - 1s 26ms/step - loss: 0.2613 - accuracy: 0.9505 - val_loss: 0.2711 - val_accuracy: 0.9333\n",
            "Q 76-57 A 19  ✅ 19 \n",
            "Q 50-47 A 3   ❌ 4  \n",
            "Q 44-30 A 14  ✅ 14 \n",
            "Q 45-15 A 30  ✅ 30 \n",
            "Q 42-46 A -4  ✅ -4 \n",
            "Q 73-78 A -5  ❌ -4 \n",
            "Q 65-87 A -22 ✅ -22\n",
            "Q 48-99 A -51 ✅ -51\n",
            "Q 79-47 A 32  ✅ 32 \n",
            "Q 31-73 A -42 ✅ -42\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 136\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 0.2507 - accuracy: 0.9545 - val_loss: 0.2574 - val_accuracy: 0.9467\n",
            "Q 76-51 A 25  ✅ 25 \n",
            "Q 91-86 A 5   ❌ 6  \n",
            "Q 54-97 A -43 ✅ -43\n",
            "Q 88-95 A -7  ✅ -7 \n",
            "Q 77-41 A 36  ✅ 36 \n",
            "Q 98-94 A 4   ❌ 3  \n",
            "Q 69-65 A 4   ❌ 3  \n",
            "Q 98-94 A 4   ❌ 3  \n",
            "Q 49-79 A -30 ✅ -30\n",
            "Q 44-30 A 14  ✅ 14 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 137\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 0.2452 - accuracy: 0.9568 - val_loss: 0.2562 - val_accuracy: 0.9450\n",
            "Q 94-14 A 80  ✅ 80 \n",
            "Q 91-86 A 5   ❌ 6  \n",
            "Q 80-63 A 17  ✅ 17 \n",
            "Q 72-85 A -13 ✅ -13\n",
            "Q 89-54 A 35  ✅ 35 \n",
            "Q 42-31 A 11  ✅ 11 \n",
            "Q 45-22 A 23  ✅ 23 \n",
            "Q 98-51 A 47  ✅ 47 \n",
            "Q 67-66 A 1   ❌ 0  \n",
            "Q 67-59 A 8   ❌ 9  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 138\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 0.2418 - accuracy: 0.9556 - val_loss: 0.2488 - val_accuracy: 0.9467\n",
            "Q 86-99 A -13 ✅ -13\n",
            "Q 62-37 A 25  ✅ 25 \n",
            "Q 33-70 A -37 ✅ -37\n",
            "Q 43-23 A 20  ✅ 20 \n",
            "Q 30-87 A -57 ✅ -57\n",
            "Q 18-88 A -70 ❌ -60\n",
            "Q 52-78 A -26 ✅ -26\n",
            "Q 76-85 A -9  ✅ -9 \n",
            "Q 48-99 A -51 ✅ -51\n",
            "Q 54-54 A 0   ✅ 0  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 139\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 0.2310 - accuracy: 0.9605 - val_loss: 0.2450 - val_accuracy: 0.9400\n",
            "Q 45-64 A -19 ✅ -19\n",
            "Q 54-54 A 0   ✅ 0  \n",
            "Q 76-83 A -7  ✅ -7 \n",
            "Q 33-77 A -44 ✅ -44\n",
            "Q 58-23 A 35  ✅ 35 \n",
            "Q 17-46 A -29 ✅ -29\n",
            "Q 13-64 A -51 ✅ -51\n",
            "Q 49-21 A 28  ✅ 28 \n",
            "Q 27-90 A -63 ✅ -63\n",
            "Q 33-78 A -45 ✅ -45\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 140\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 0.2275 - accuracy: 0.9590 - val_loss: 0.2394 - val_accuracy: 0.9458\n",
            "Q 65-64 A 1   ✅ 1  \n",
            "Q 31-17 A 14  ❌ 13 \n",
            "Q 44-27 A 17  ✅ 17 \n",
            "Q 28-33 A -5  ✅ -5 \n",
            "Q 26-98 A -72 ❌ -73\n",
            "Q 41-95 A -54 ✅ -54\n",
            "Q 76-83 A -7  ✅ -7 \n",
            "Q 66-56 A 10  ✅ 10 \n",
            "Q 93-34 A 59  ✅ 59 \n",
            "Q 28-33 A -5  ✅ -5 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 141\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 0.2210 - accuracy: 0.9651 - val_loss: 0.2420 - val_accuracy: 0.9458\n",
            "Q 19-62 A -43 ✅ -43\n",
            "Q 80-54 A 26  ✅ 26 \n",
            "Q 52-36 A 16  ✅ 16 \n",
            "Q 86-99 A -13 ✅ -13\n",
            "Q 65-64 A 1   ✅ 1  \n",
            "Q 15-70 A -55 ✅ -55\n",
            "Q 14-63 A -49 ✅ -49\n",
            "Q 14-34 A -20 ❌ -10\n",
            "Q 73-32 A 41  ✅ 41 \n",
            "Q 41-68 A -27 ✅ -27\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 142\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 0.2198 - accuracy: 0.9610 - val_loss: 0.2211 - val_accuracy: 0.9575\n",
            "Q 60-31 A 29  ✅ 29 \n",
            "Q 64-82 A -18 ✅ -18\n",
            "Q 84-76 A 8   ✅ 8  \n",
            "Q 95-51 A 44  ✅ 44 \n",
            "Q 61-45 A 16  ✅ 16 \n",
            "Q 90-41 A 49  ✅ 49 \n",
            "Q 42-93 A -51 ✅ -51\n",
            "Q 15-83 A -68 ✅ -68\n",
            "Q 52-60 A -8  ✅ -8 \n",
            "Q 85-64 A 21  ✅ 21 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 143\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 0.2084 - accuracy: 0.9680 - val_loss: 0.2207 - val_accuracy: 0.9567\n",
            "Q 52-36 A 16  ✅ 16 \n",
            "Q 62-70 A -8  ✅ -8 \n",
            "Q 34-46 A -12 ✅ -12\n",
            "Q 38-80 A -42 ✅ -42\n",
            "Q 98-74 A 24  ✅ 24 \n",
            "Q 53-73 A -20 ✅ -20\n",
            "Q 43-58 A -15 ✅ -15\n",
            "Q 80-45 A 35  ✅ 35 \n",
            "Q 49-79 A -30 ✅ -30\n",
            "Q 73-78 A -5  ✅ -5 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 144\n",
            "36/36 [==============================] - 1s 31ms/step - loss: 0.2068 - accuracy: 0.9656 - val_loss: 0.2159 - val_accuracy: 0.9517\n",
            "Q 39-46 A -7  ✅ -7 \n",
            "Q 48-99 A -51 ✅ -51\n",
            "Q 54-97 A -43 ✅ -43\n",
            "Q 76-51 A 25  ✅ 25 \n",
            "Q 69-83 A -14 ✅ -14\n",
            "Q 38-27 A 11  ✅ 11 \n",
            "Q 86-86 A 0   ❌ -  \n",
            "Q 41-37 A 4   ✅ 4  \n",
            "Q 69-65 A 4   ❌ 3  \n",
            "Q 42-83 A -41 ✅ -41\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 145\n",
            "36/36 [==============================] - 1s 26ms/step - loss: 0.2024 - accuracy: 0.9664 - val_loss: 0.2150 - val_accuracy: 0.9542\n",
            "Q 35-46 A -11 ✅ -11\n",
            "Q 21-66 A -45 ✅ -45\n",
            "Q 73-78 A -5  ✅ -5 \n",
            "Q 26-79 A -53 ✅ -53\n",
            "Q 38-92 A -54 ❌ -55\n",
            "Q 53-48 A 5   ❌ 4  \n",
            "Q 65-32 A 33  ✅ 33 \n",
            "Q 26-68 A -42 ✅ -42\n",
            "Q 15-63 A -48 ✅ -48\n",
            "Q 74-61 A 13  ✅ 13 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 146\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 0.1952 - accuracy: 0.9687 - val_loss: 0.2051 - val_accuracy: 0.9592\n",
            "Q 98-94 A 4   ✅ 4  \n",
            "Q 26-74 A -48 ✅ -48\n",
            "Q 71-32 A 39  ✅ 39 \n",
            "Q 88-76 A 12  ✅ 12 \n",
            "Q 39-73 A -34 ✅ -34\n",
            "Q 76-51 A 25  ✅ 25 \n",
            "Q 72-37 A 35  ✅ 35 \n",
            "Q 18-88 A -70 ✅ -70\n",
            "Q 71-80 A -9  ✅ -9 \n",
            "Q 99-39 A 60  ❌ 50 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 147\n",
            "36/36 [==============================] - 1s 26ms/step - loss: 0.1890 - accuracy: 0.9706 - val_loss: 0.2041 - val_accuracy: 0.9592\n",
            "Q 22-88 A -66 ✅ -66\n",
            "Q 47-81 A -34 ✅ -34\n",
            "Q 41-73 A -32 ✅ -32\n",
            "Q 12-48 A -36 ✅ -36\n",
            "Q 64-61 A 3   ❌ 1  \n",
            "Q 11-19 A -8  ✅ -8 \n",
            "Q 71-34 A 37  ✅ 37 \n",
            "Q 16-94 A -78 ✅ -78\n",
            "Q 72-35 A 37  ✅ 37 \n",
            "Q 63-17 A 46  ✅ 46 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 148\n",
            "36/36 [==============================] - 1s 26ms/step - loss: 0.1871 - accuracy: 0.9714 - val_loss: 0.1982 - val_accuracy: 0.9650\n",
            "Q 65-65 A 0   ❌ -  \n",
            "Q 71-17 A 54  ✅ 54 \n",
            "Q 13-72 A -59 ✅ -59\n",
            "Q 30-62 A -32 ✅ -32\n",
            "Q 46-40 A 6   ❌ 7  \n",
            "Q 28-52 A -24 ✅ -24\n",
            "Q 63-26 A 37  ✅ 37 \n",
            "Q 66-56 A 10  ✅ 10 \n",
            "Q 52-83 A -31 ✅ -31\n",
            "Q 86-86 A 0   ❌ -  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 149\n",
            "36/36 [==============================] - 1s 26ms/step - loss: 0.1813 - accuracy: 0.9710 - val_loss: 0.1953 - val_accuracy: 0.9625\n",
            "Q 16-94 A -78 ✅ -78\n",
            "Q 57-64 A -7  ✅ -7 \n",
            "Q 29-51 A -22 ✅ -22\n",
            "Q 50-34 A 16  ✅ 16 \n",
            "Q 41-37 A 4   ✅ 4  \n",
            "Q 67-59 A 8   ✅ 8  \n",
            "Q 60-34 A 26  ✅ 26 \n",
            "Q 44-27 A 17  ✅ 17 \n",
            "Q 72-14 A 58  ✅ 58 \n",
            "Q 27-94 A -67 ✅ -67\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 150\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 0.1750 - accuracy: 0.9747 - val_loss: 0.1876 - val_accuracy: 0.9633\n",
            "Q 57-22 A 35  ✅ 35 \n",
            "Q 55-70 A -15 ✅ -15\n",
            "Q 17-93 A -76 ✅ -76\n",
            "Q 92-32 A 60  ✅ 60 \n",
            "Q 85-47 A 38  ✅ 38 \n",
            "Q 90-19 A 71  ❌ 62 \n",
            "Q 59-50 A 9   ❌ 7  \n",
            "Q 12-62 A -50 ✅ -50\n",
            "Q 63-23 A 40  ✅ 40 \n",
            "Q 45-15 A 30  ✅ 30 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 151\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 0.1787 - accuracy: 0.9725 - val_loss: 0.2084 - val_accuracy: 0.9475\n",
            "Q 32-60 A -28 ✅ -28\n",
            "Q 55-11 A 44  ✅ 44 \n",
            "Q 69-65 A 4   ❌ 1  \n",
            "Q 61-77 A -16 ✅ -16\n",
            "Q 53-73 A -20 ✅ -20\n",
            "Q 45-15 A 30  ✅ 30 \n",
            "Q 65-53 A 12  ✅ 12 \n",
            "Q 36-33 A 3   ✅ 3  \n",
            "Q 35-47 A -12 ✅ -12\n",
            "Q 89-54 A 35  ✅ 35 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 152\n",
            "36/36 [==============================] - 1s 26ms/step - loss: 0.1711 - accuracy: 0.9743 - val_loss: 0.1798 - val_accuracy: 0.9675\n",
            "Q 80-45 A 35  ✅ 35 \n",
            "Q 34-24 A 10  ✅ 10 \n",
            "Q 83-67 A 16  ✅ 16 \n",
            "Q 38-92 A -54 ✅ -54\n",
            "Q 72-37 A 35  ✅ 35 \n",
            "Q 13-30 A -17 ✅ -17\n",
            "Q 35-46 A -11 ✅ -11\n",
            "Q 12-62 A -50 ✅ -50\n",
            "Q 49-69 A -20 ✅ -20\n",
            "Q 28-33 A -5  ✅ -5 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 153\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 0.1672 - accuracy: 0.9738 - val_loss: 0.1834 - val_accuracy: 0.9642\n",
            "Q 53-48 A 5   ❌ 4  \n",
            "Q 50-33 A 17  ✅ 17 \n",
            "Q 90-58 A 32  ✅ 32 \n",
            "Q 64-82 A -18 ✅ -18\n",
            "Q 40-11 A 29  ✅ 29 \n",
            "Q 47-84 A -37 ✅ -37\n",
            "Q 94-38 A 56  ✅ 56 \n",
            "Q 92-51 A 41  ✅ 41 \n",
            "Q 14-31 A -17 ✅ -17\n",
            "Q 52-83 A -31 ✅ -31\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 154\n",
            "36/36 [==============================] - 1s 26ms/step - loss: 0.1679 - accuracy: 0.9724 - val_loss: 0.1785 - val_accuracy: 0.9633\n",
            "Q 97-35 A 62  ✅ 62 \n",
            "Q 42-78 A -36 ✅ -36\n",
            "Q 28-95 A -67 ✅ -67\n",
            "Q 87-74 A 13  ✅ 13 \n",
            "Q 76-16 A 60  ✅ 60 \n",
            "Q 33-42 A -9  ✅ -9 \n",
            "Q 84-76 A 8   ❌ 1  \n",
            "Q 47-57 A -10 ✅ -10\n",
            "Q 37-63 A -26 ✅ -26\n",
            "Q 66-33 A 33  ✅ 33 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 155\n",
            "36/36 [==============================] - 1s 26ms/step - loss: 0.1751 - accuracy: 0.9657 - val_loss: 0.1876 - val_accuracy: 0.9625\n",
            "Q 98-94 A 4   ✅ 4  \n",
            "Q 72-35 A 37  ✅ 37 \n",
            "Q 29-50 A -21 ✅ -21\n",
            "Q 89-54 A 35  ❌ 45 \n",
            "Q 64-61 A 3   ✅ 3  \n",
            "Q 47-55 A -8  ✅ -8 \n",
            "Q 62-88 A -26 ✅ -26\n",
            "Q 57-33 A 24  ✅ 24 \n",
            "Q 31-12 A 19  ✅ 19 \n",
            "Q 59-50 A 9   ❌ 7  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 156\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 0.1630 - accuracy: 0.9734 - val_loss: 0.1729 - val_accuracy: 0.9667\n",
            "Q 94-66 A 28  ✅ 28 \n",
            "Q 27-90 A -63 ✅ -63\n",
            "Q 72-18 A 54  ✅ 54 \n",
            "Q 62-38 A 24  ✅ 24 \n",
            "Q 65-17 A 48  ✅ 48 \n",
            "Q 62-48 A 14  ✅ 14 \n",
            "Q 46-90 A -44 ✅ -44\n",
            "Q 33-56 A -23 ✅ -23\n",
            "Q 88-76 A 12  ✅ 12 \n",
            "Q 81-74 A 7   ✅ 7  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 157\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 0.1480 - accuracy: 0.9775 - val_loss: 0.1623 - val_accuracy: 0.9700\n",
            "Q 16-70 A -54 ❌ -55\n",
            "Q 98-63 A 35  ✅ 35 \n",
            "Q 90-99 A -9  ✅ -9 \n",
            "Q 48-87 A -39 ✅ -39\n",
            "Q 30-71 A -41 ✅ -41\n",
            "Q 59-14 A 45  ✅ 45 \n",
            "Q 67-59 A 8   ✅ 8  \n",
            "Q 85-64 A 21  ✅ 21 \n",
            "Q 42-83 A -41 ✅ -41\n",
            "Q 70-11 A 59  ❌ 69 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 158\n",
            "36/36 [==============================] - 1s 30ms/step - loss: 0.1425 - accuracy: 0.9808 - val_loss: 0.1595 - val_accuracy: 0.9717\n",
            "Q 49-21 A 28  ✅ 28 \n",
            "Q 74-29 A 45  ✅ 45 \n",
            "Q 21-66 A -45 ✅ -45\n",
            "Q 23-54 A -31 ✅ -31\n",
            "Q 93-76 A 17  ✅ 17 \n",
            "Q 79-23 A 56  ✅ 56 \n",
            "Q 74-61 A 13  ✅ 13 \n",
            "Q 42-46 A -4  ✅ -4 \n",
            "Q 28-33 A -5  ✅ -5 \n",
            "Q 21-63 A -42 ✅ -42\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 159\n",
            "36/36 [==============================] - 1s 27ms/step - loss: 0.1382 - accuracy: 0.9819 - val_loss: 0.1557 - val_accuracy: 0.9750\n",
            "Q 58-53 A 5   ✅ 5  \n",
            "Q 14-66 A -52 ✅ -52\n",
            "Q 54-14 A 40  ✅ 40 \n",
            "Q 73-51 A 22  ✅ 22 \n",
            "Q 26-68 A -42 ✅ -42\n",
            "Q 31-15 A 16  ✅ 16 \n",
            "Q 29-51 A -22 ✅ -22\n",
            "Q 34-57 A -23 ✅ -23\n",
            "Q 31-23 A 8   ✅ 8  \n",
            "Q 44-75 A -31 ✅ -31\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 160\n",
            "36/36 [==============================] - 1s 26ms/step - loss: 0.1363 - accuracy: 0.9815 - val_loss: 0.1548 - val_accuracy: 0.9717\n",
            "Q 33-82 A -49 ✅ -49\n",
            "Q 27-90 A -63 ✅ -63\n",
            "Q 31-81 A -50 ✅ -50\n",
            "Q 37-85 A -48 ✅ -48\n",
            "Q 48-87 A -39 ✅ -39\n",
            "Q 96-46 A 50  ❌ 40 \n",
            "Q 74-29 A 45  ✅ 45 \n",
            "Q 19-49 A -30 ✅ -30\n",
            "Q 41-73 A -32 ✅ -32\n",
            "Q 89-54 A 35  ✅ 35 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 161\n",
            "36/36 [==============================] - 1s 26ms/step - loss: 0.1333 - accuracy: 0.9825 - val_loss: 0.1535 - val_accuracy: 0.9742\n",
            "Q 80-54 A 26  ✅ 26 \n",
            "Q 62-50 A 12  ✅ 12 \n",
            "Q 17-93 A -76 ✅ -76\n",
            "Q 72-37 A 35  ✅ 35 \n",
            "Q 95-51 A 44  ✅ 44 \n",
            "Q 24-33 A -9  ✅ -9 \n",
            "Q 70-77 A -7  ✅ -7 \n",
            "Q 47-84 A -37 ✅ -37\n",
            "Q 57-83 A -26 ✅ -26\n",
            "Q 65-17 A 48  ✅ 48 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 162\n",
            "36/36 [==============================] - 1s 26ms/step - loss: 0.1291 - accuracy: 0.9838 - val_loss: 0.1497 - val_accuracy: 0.9733\n",
            "Q 58-53 A 5   ✅ 5  \n",
            "Q 57-55 A 2   ❌ 1  \n",
            "Q 94-38 A 56  ✅ 56 \n",
            "Q 99-31 A 68  ❌ 67 \n",
            "Q 28-52 A -24 ✅ -24\n",
            "Q 36-23 A 13  ✅ 13 \n",
            "Q 26-17 A 9   ❌ 10 \n",
            "Q 99-17 A 82  ✅ 82 \n",
            "Q 15-70 A -55 ✅ -55\n",
            "Q 66-45 A 21  ❌ 22 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 163\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 0.1250 - accuracy: 0.9865 - val_loss: 0.1421 - val_accuracy: 0.9792\n",
            "Q 80-82 A -2  ✅ -2 \n",
            "Q 52-13 A 39  ✅ 39 \n",
            "Q 81-91 A -10 ✅ -10\n",
            "Q 62-88 A -26 ✅ -26\n",
            "Q 31-15 A 16  ✅ 16 \n",
            "Q 65-87 A -22 ✅ -22\n",
            "Q 79-23 A 56  ✅ 56 \n",
            "Q 21-30 A -9  ✅ -9 \n",
            "Q 32-20 A 12  ✅ 12 \n",
            "Q 33-70 A -37 ✅ -37\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 164\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 0.1258 - accuracy: 0.9830 - val_loss: 0.1549 - val_accuracy: 0.9650\n",
            "Q 71-91 A -20 ✅ -20\n",
            "Q 44-30 A 14  ✅ 14 \n",
            "Q 28-39 A -11 ✅ -11\n",
            "Q 31-47 A -16 ✅ -16\n",
            "Q 53-22 A 31  ✅ 31 \n",
            "Q 60-34 A 26  ✅ 26 \n",
            "Q 81-74 A 7   ✅ 7  \n",
            "Q 38-21 A 17  ✅ 17 \n",
            "Q 73-51 A 22  ✅ 22 \n",
            "Q 36-33 A 3   ✅ 3  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 165\n",
            "36/36 [==============================] - 1s 26ms/step - loss: 0.1491 - accuracy: 0.9692 - val_loss: 0.1689 - val_accuracy: 0.9583\n",
            "Q 65-32 A 33  ✅ 33 \n",
            "Q 41-96 A -55 ✅ -55\n",
            "Q 55-11 A 44  ✅ 44 \n",
            "Q 44-96 A -52 ✅ -52\n",
            "Q 48-87 A -39 ❌ -49\n",
            "Q 80-39 A 41  ❌ 42 \n",
            "Q 65-17 A 48  ✅ 48 \n",
            "Q 32-23 A 9   ❌ 10 \n",
            "Q 69-83 A -14 ✅ -14\n",
            "Q 40-52 A -12 ✅ -12\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 166\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 0.1431 - accuracy: 0.9732 - val_loss: 0.1572 - val_accuracy: 0.9650\n",
            "Q 82-41 A 41  ✅ 41 \n",
            "Q 89-25 A 64  ✅ 64 \n",
            "Q 50-34 A 16  ✅ 16 \n",
            "Q 60-71 A -11 ✅ -11\n",
            "Q 13-64 A -51 ✅ -51\n",
            "Q 19-62 A -43 ✅ -43\n",
            "Q 69-41 A 28  ✅ 28 \n",
            "Q 34-26 A 8   ✅ 8  \n",
            "Q 31-15 A 16  ✅ 16 \n",
            "Q 39-96 A -57 ✅ -57\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 167\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 0.1274 - accuracy: 0.9828 - val_loss: 0.1489 - val_accuracy: 0.9742\n",
            "Q 15-51 A -36 ✅ -36\n",
            "Q 47-57 A -10 ✅ -10\n",
            "Q 60-71 A -11 ✅ -11\n",
            "Q 71-32 A 39  ✅ 39 \n",
            "Q 34-57 A -23 ✅ -23\n",
            "Q 31-28 A 3   ❌ 4  \n",
            "Q 86-54 A 32  ✅ 32 \n",
            "Q 97-60 A 37  ✅ 37 \n",
            "Q 34-46 A -12 ✅ -12\n",
            "Q 44-21 A 23  ✅ 23 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 168\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 0.1171 - accuracy: 0.9850 - val_loss: 0.1344 - val_accuracy: 0.9783\n",
            "Q 65-87 A -22 ✅ -22\n",
            "Q 91-54 A 37  ✅ 37 \n",
            "Q 74-51 A 23  ✅ 23 \n",
            "Q 47-57 A -10 ✅ -10\n",
            "Q 16-70 A -54 ✅ -54\n",
            "Q 90-19 A 71  ❌ 72 \n",
            "Q 42-46 A -4  ✅ -4 \n",
            "Q 31-23 A 8   ✅ 8  \n",
            "Q 44-30 A 14  ✅ 14 \n",
            "Q 75-16 A 59  ❌ 69 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 169\n",
            "36/36 [==============================] - 1s 26ms/step - loss: 0.1119 - accuracy: 0.9867 - val_loss: 0.1367 - val_accuracy: 0.9775\n",
            "Q 35-46 A -11 ✅ -11\n",
            "Q 39-46 A -7  ✅ -7 \n",
            "Q 33-42 A -9  ✅ -9 \n",
            "Q 64-12 A 52  ✅ 52 \n",
            "Q 77-67 A 10  ✅ 10 \n",
            "Q 52-83 A -31 ✅ -31\n",
            "Q 32-20 A 12  ✅ 12 \n",
            "Q 52-11 A 41  ✅ 41 \n",
            "Q 75-16 A 59  ✅ 59 \n",
            "Q 21-30 A -9  ✅ -9 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 170\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 0.1117 - accuracy: 0.9874 - val_loss: 0.1331 - val_accuracy: 0.9725\n",
            "Q 34-24 A 10  ✅ 10 \n",
            "Q 55-99 A -44 ✅ -44\n",
            "Q 53-70 A -17 ✅ -17\n",
            "Q 74-93 A -19 ✅ -19\n",
            "Q 32-23 A 9   ❌ 10 \n",
            "Q 51-14 A 37  ✅ 37 \n",
            "Q 68-83 A -15 ✅ -15\n",
            "Q 65-80 A -15 ✅ -15\n",
            "Q 71-80 A -9  ✅ -9 \n",
            "Q 71-17 A 54  ✅ 54 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 171\n",
            "36/36 [==============================] - 1s 26ms/step - loss: 0.1102 - accuracy: 0.9863 - val_loss: 0.1319 - val_accuracy: 0.9758\n",
            "Q 31-92 A -61 ✅ -61\n",
            "Q 49-21 A 28  ✅ 28 \n",
            "Q 24-32 A -8  ✅ -8 \n",
            "Q 45-99 A -54 ✅ -54\n",
            "Q 87-61 A 26  ✅ 26 \n",
            "Q 62-95 A -33 ✅ -33\n",
            "Q 91-66 A 25  ✅ 25 \n",
            "Q 52-36 A 16  ✅ 16 \n",
            "Q 66-87 A -21 ✅ -21\n",
            "Q 38-80 A -42 ✅ -42\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 172\n",
            "36/36 [==============================] - 1s 26ms/step - loss: 0.1073 - accuracy: 0.9866 - val_loss: 0.1256 - val_accuracy: 0.9783\n",
            "Q 69-91 A -22 ❌ -21\n",
            "Q 77-41 A 36  ✅ 36 \n",
            "Q 87-74 A 13  ✅ 13 \n",
            "Q 98-51 A 47  ✅ 47 \n",
            "Q 34-44 A -10 ✅ -10\n",
            "Q 37-94 A -57 ✅ -57\n",
            "Q 20-42 A -22 ✅ -22\n",
            "Q 70-71 A -1  ✅ -1 \n",
            "Q 62-50 A 12  ✅ 12 \n",
            "Q 54-14 A 40  ✅ 40 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 173\n",
            "36/36 [==============================] - 1s 32ms/step - loss: 0.1046 - accuracy: 0.9887 - val_loss: 0.1220 - val_accuracy: 0.9792\n",
            "Q 21-30 A -9  ✅ -9 \n",
            "Q 13-72 A -59 ❌ -69\n",
            "Q 66-33 A 33  ✅ 33 \n",
            "Q 58-53 A 5   ✅ 5  \n",
            "Q 58-82 A -24 ✅ -24\n",
            "Q 69-65 A 4   ❌ 3  \n",
            "Q 33-77 A -44 ✅ -44\n",
            "Q 11-29 A -18 ✅ -18\n",
            "Q 14-75 A -61 ✅ -61\n",
            "Q 93-89 A 4   ✅ 4  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 174\n",
            "36/36 [==============================] - 1s 26ms/step - loss: 0.1006 - accuracy: 0.9889 - val_loss: 0.1200 - val_accuracy: 0.9808\n",
            "Q 14-92 A -78 ✅ -78\n",
            "Q 74-61 A 13  ✅ 13 \n",
            "Q 30-34 A -4  ✅ -4 \n",
            "Q 15-85 A -70 ✅ -70\n",
            "Q 54-97 A -43 ✅ -43\n",
            "Q 48-59 A -11 ✅ -11\n",
            "Q 62-38 A 24  ✅ 24 \n",
            "Q 96-46 A 50  ❌ 40 \n",
            "Q 14-92 A -78 ✅ -78\n",
            "Q 87-61 A 26  ✅ 26 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 175\n",
            "36/36 [==============================] - 1s 26ms/step - loss: 0.0966 - accuracy: 0.9888 - val_loss: 0.1190 - val_accuracy: 0.9808\n",
            "Q 72-64 A 8   ✅ 8  \n",
            "Q 13-64 A -51 ✅ -51\n",
            "Q 77-29 A 48  ✅ 48 \n",
            "Q 48-99 A -51 ✅ -51\n",
            "Q 13-64 A -51 ✅ -51\n",
            "Q 71-91 A -20 ✅ -20\n",
            "Q 45-64 A -19 ✅ -19\n",
            "Q 53-73 A -20 ✅ -20\n",
            "Q 48-72 A -24 ✅ -24\n",
            "Q 19-62 A -43 ✅ -43\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 176\n",
            "36/36 [==============================] - 1s 26ms/step - loss: 0.0954 - accuracy: 0.9895 - val_loss: 0.1120 - val_accuracy: 0.9825\n",
            "Q 73-43 A 30  ✅ 30 \n",
            "Q 42-46 A -4  ✅ -4 \n",
            "Q 75-16 A 59  ✅ 59 \n",
            "Q 99-17 A 82  ✅ 82 \n",
            "Q 91-66 A 25  ✅ 25 \n",
            "Q 13-42 A -29 ✅ -29\n",
            "Q 33-70 A -37 ✅ -37\n",
            "Q 69-65 A 4   ❌ 3  \n",
            "Q 47-60 A -13 ✅ -13\n",
            "Q 50-34 A 16  ✅ 16 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 177\n",
            "36/36 [==============================] - 1s 26ms/step - loss: 0.0941 - accuracy: 0.9896 - val_loss: 0.1113 - val_accuracy: 0.9808\n",
            "Q 24-32 A -8  ✅ -8 \n",
            "Q 84-33 A 51  ✅ 51 \n",
            "Q 76-51 A 25  ✅ 25 \n",
            "Q 88-95 A -7  ✅ -7 \n",
            "Q 11-24 A -13 ✅ -13\n",
            "Q 52-78 A -26 ✅ -26\n",
            "Q 38-27 A 11  ✅ 11 \n",
            "Q 57-55 A 2   ❌ 1  \n",
            "Q 71-26 A 45  ✅ 45 \n",
            "Q 73-51 A 22  ✅ 22 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 178\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 0.0911 - accuracy: 0.9908 - val_loss: 0.1091 - val_accuracy: 0.9850\n",
            "Q 98-63 A 35  ✅ 35 \n",
            "Q 46-15 A 31  ✅ 31 \n",
            "Q 61-77 A -16 ✅ -16\n",
            "Q 65-35 A 30  ❌ 20 \n",
            "Q 18-88 A -70 ✅ -70\n",
            "Q 14-66 A -52 ✅ -52\n",
            "Q 86-86 A 0   ✅ 0  \n",
            "Q 58-57 A 1   ✅ 1  \n",
            "Q 14-71 A -57 ✅ -57\n",
            "Q 36-31 A 5   ✅ 5  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 179\n",
            "36/36 [==============================] - 1s 26ms/step - loss: 0.0885 - accuracy: 0.9904 - val_loss: 0.1086 - val_accuracy: 0.9858\n",
            "Q 74-93 A -19 ✅ -19\n",
            "Q 23-54 A -31 ✅ -31\n",
            "Q 89-91 A -2  ✅ -2 \n",
            "Q 86-11 A 75  ✅ 75 \n",
            "Q 89-25 A 64  ✅ 64 \n",
            "Q 66-56 A 10  ✅ 10 \n",
            "Q 53-63 A -10 ✅ -10\n",
            "Q 98-63 A 35  ✅ 35 \n",
            "Q 89-59 A 30  ❌ 20 \n",
            "Q 65-64 A 1   ✅ 1  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 180\n",
            "36/36 [==============================] - 1s 26ms/step - loss: 0.0874 - accuracy: 0.9909 - val_loss: 0.1089 - val_accuracy: 0.9825\n",
            "Q 40-71 A -31 ✅ -31\n",
            "Q 16-44 A -28 ✅ -28\n",
            "Q 39-55 A -16 ✅ -16\n",
            "Q 32-23 A 9   ❌ 1  \n",
            "Q 67-86 A -19 ✅ -19\n",
            "Q 44-30 A 14  ✅ 14 \n",
            "Q 33-48 A -15 ✅ -15\n",
            "Q 13-72 A -59 ❌ -69\n",
            "Q 60-63 A -3  ✅ -3 \n",
            "Q 31-15 A 16  ✅ 16 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 181\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 0.0854 - accuracy: 0.9909 - val_loss: 0.1119 - val_accuracy: 0.9800\n",
            "Q 86-54 A 32  ✅ 32 \n",
            "Q 30-34 A -4  ✅ -4 \n",
            "Q 68-14 A 54  ✅ 54 \n",
            "Q 79-23 A 56  ✅ 56 \n",
            "Q 46-15 A 31  ✅ 31 \n",
            "Q 31-73 A -42 ✅ -42\n",
            "Q 41-11 A 30  ✅ 30 \n",
            "Q 38-92 A -54 ✅ -54\n",
            "Q 93-60 A 33  ✅ 33 \n",
            "Q 15-85 A -70 ✅ -70\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 182\n",
            "36/36 [==============================] - 1s 26ms/step - loss: 0.0850 - accuracy: 0.9905 - val_loss: 0.1020 - val_accuracy: 0.9850\n",
            "Q 81-32 A 49  ✅ 49 \n",
            "Q 59-50 A 9   ❌ 8  \n",
            "Q 33-70 A -37 ✅ -37\n",
            "Q 35-46 A -11 ✅ -11\n",
            "Q 76-57 A 19  ✅ 19 \n",
            "Q 81-53 A 28  ✅ 28 \n",
            "Q 34-44 A -10 ✅ -10\n",
            "Q 17-93 A -76 ✅ -76\n",
            "Q 66-56 A 10  ✅ 10 \n",
            "Q 65-80 A -15 ✅ -15\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 183\n",
            "36/36 [==============================] - 1s 26ms/step - loss: 0.0865 - accuracy: 0.9900 - val_loss: 0.1046 - val_accuracy: 0.9833\n",
            "Q 69-83 A -14 ✅ -14\n",
            "Q 67-43 A 24  ✅ 24 \n",
            "Q 72-35 A 37  ✅ 37 \n",
            "Q 39-46 A -7  ✅ -7 \n",
            "Q 57-83 A -26 ✅ -26\n",
            "Q 88-76 A 12  ✅ 12 \n",
            "Q 28-52 A -24 ✅ -24\n",
            "Q 81-32 A 49  ✅ 49 \n",
            "Q 71-32 A 39  ✅ 39 \n",
            "Q 77-12 A 65  ✅ 65 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 184\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 0.0835 - accuracy: 0.9919 - val_loss: 0.1030 - val_accuracy: 0.9808\n",
            "Q 43-58 A -15 ✅ -15\n",
            "Q 62-38 A 24  ✅ 24 \n",
            "Q 52-78 A -26 ✅ -26\n",
            "Q 89-91 A -2  ✅ -2 \n",
            "Q 38-80 A -42 ✅ -42\n",
            "Q 33-56 A -23 ✅ -23\n",
            "Q 55-99 A -44 ✅ -44\n",
            "Q 62-50 A 12  ✅ 12 \n",
            "Q 14-34 A -20 ✅ -20\n",
            "Q 33-42 A -9  ✅ -9 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 185\n",
            "36/36 [==============================] - 1s 26ms/step - loss: 0.0804 - accuracy: 0.9929 - val_loss: 0.0997 - val_accuracy: 0.9858\n",
            "Q 66-87 A -21 ✅ -21\n",
            "Q 59-50 A 9   ❌ 8  \n",
            "Q 20-65 A -45 ✅ -45\n",
            "Q 99-81 A 18  ✅ 18 \n",
            "Q 35-46 A -11 ✅ -11\n",
            "Q 24-32 A -8  ✅ -8 \n",
            "Q 27-13 A 14  ✅ 14 \n",
            "Q 77-41 A 36  ✅ 36 \n",
            "Q 75-52 A 23  ✅ 23 \n",
            "Q 43-58 A -15 ✅ -15\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 186\n",
            "36/36 [==============================] - 1s 27ms/step - loss: 0.0783 - accuracy: 0.9931 - val_loss: 0.1009 - val_accuracy: 0.9842\n",
            "Q 84-96 A -12 ✅ -12\n",
            "Q 47-55 A -8  ✅ -8 \n",
            "Q 40-68 A -28 ✅ -28\n",
            "Q 60-51 A 9   ✅ 9  \n",
            "Q 43-98 A -55 ✅ -55\n",
            "Q 67-86 A -19 ✅ -19\n",
            "Q 69-41 A 28  ✅ 28 \n",
            "Q 44-27 A 17  ✅ 17 \n",
            "Q 14-66 A -52 ✅ -52\n",
            "Q 77-41 A 36  ✅ 36 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 187\n",
            "36/36 [==============================] - 1s 32ms/step - loss: 0.0759 - accuracy: 0.9931 - val_loss: 0.0949 - val_accuracy: 0.9825\n",
            "Q 79-81 A -2  ✅ -2 \n",
            "Q 76-85 A -9  ✅ -9 \n",
            "Q 41-60 A -19 ✅ -19\n",
            "Q 98-51 A 47  ✅ 47 \n",
            "Q 15-29 A -14 ✅ -14\n",
            "Q 34-44 A -10 ✅ -10\n",
            "Q 72-64 A 8   ✅ 8  \n",
            "Q 71-42 A 29  ✅ 29 \n",
            "Q 53-48 A 5   ✅ 5  \n",
            "Q 11-24 A -13 ✅ -13\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 188\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 0.0737 - accuracy: 0.9933 - val_loss: 0.0945 - val_accuracy: 0.9867\n",
            "Q 44-27 A 17  ✅ 17 \n",
            "Q 95-27 A 68  ✅ 68 \n",
            "Q 65-64 A 1   ✅ 1  \n",
            "Q 67-59 A 8   ✅ 8  \n",
            "Q 77-12 A 65  ✅ 65 \n",
            "Q 98-51 A 47  ✅ 47 \n",
            "Q 17-93 A -76 ✅ -76\n",
            "Q 35-15 A 20  ✅ 20 \n",
            "Q 97-60 A 37  ✅ 37 \n",
            "Q 31-73 A -42 ✅ -42\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 189\n",
            "36/36 [==============================] - 1s 26ms/step - loss: 0.0739 - accuracy: 0.9927 - val_loss: 0.0955 - val_accuracy: 0.9850\n",
            "Q 94-66 A 28  ✅ 28 \n",
            "Q 93-78 A 15  ✅ 15 \n",
            "Q 16-44 A -28 ✅ -28\n",
            "Q 60-31 A 29  ✅ 29 \n",
            "Q 95-51 A 44  ✅ 44 \n",
            "Q 87-61 A 26  ✅ 26 \n",
            "Q 62-42 A 20  ✅ 20 \n",
            "Q 79-81 A -2  ✅ -2 \n",
            "Q 34-44 A -10 ✅ -10\n",
            "Q 35-89 A -54 ✅ -54\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 190\n",
            "36/36 [==============================] - 1s 26ms/step - loss: 0.0750 - accuracy: 0.9918 - val_loss: 0.1025 - val_accuracy: 0.9825\n",
            "Q 24-90 A -66 ✅ -66\n",
            "Q 62-48 A 14  ✅ 14 \n",
            "Q 86-14 A 72  ✅ 72 \n",
            "Q 15-83 A -68 ✅ -68\n",
            "Q 94-14 A 80  ✅ 80 \n",
            "Q 52-83 A -31 ✅ -31\n",
            "Q 28-52 A -24 ✅ -24\n",
            "Q 71-42 A 29  ✅ 29 \n",
            "Q 11-24 A -13 ✅ -13\n",
            "Q 79-23 A 56  ✅ 56 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 191\n",
            "36/36 [==============================] - 1s 26ms/step - loss: 0.1051 - accuracy: 0.9772 - val_loss: 0.2940 - val_accuracy: 0.9083\n",
            "Q 54-33 A 21  ✅ 21 \n",
            "Q 13-67 A -54 ✅ -54\n",
            "Q 53-73 A -20 ✅ -20\n",
            "Q 62-88 A -26 ✅ -26\n",
            "Q 62-50 A 12  ✅ 12 \n",
            "Q 20-65 A -45 ✅ -45\n",
            "Q 70-71 A -1  ✅ -1 \n",
            "Q 92-29 A 63  ✅ 63 \n",
            "Q 83-67 A 16  ✅ 16 \n",
            "Q 38-27 A 11  ❌ 1  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 192\n",
            "36/36 [==============================] - 1s 25ms/step - loss: 0.2102 - accuracy: 0.9355 - val_loss: 0.1607 - val_accuracy: 0.9567\n",
            "Q 55-70 A -15 ✅ -15\n",
            "Q 26-60 A -34 ✅ -34\n",
            "Q 43-21 A 22  ✅ 22 \n",
            "Q 27-90 A -63 ✅ -63\n",
            "Q 42-83 A -41 ✅ -41\n",
            "Q 65-87 A -22 ✅ -22\n",
            "Q 31-47 A -16 ✅ -16\n",
            "Q 13-56 A -43 ❌ -44\n",
            "Q 98-85 A 13  ✅ 13 \n",
            "Q 27-96 A -69 ✅ -69\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 193\n",
            "36/36 [==============================] - 1s 27ms/step - loss: 0.1031 - accuracy: 0.9799 - val_loss: 0.1025 - val_accuracy: 0.9808\n",
            "Q 82-41 A 41  ✅ 41 \n",
            "Q 69-65 A 4   ❌ 3  \n",
            "Q 13-64 A -51 ✅ -51\n",
            "Q 58-23 A 35  ✅ 35 \n",
            "Q 69-91 A -22 ✅ -22\n",
            "Q 72-37 A 35  ✅ 35 \n",
            "Q 99-37 A 62  ✅ 62 \n",
            "Q 77-67 A 10  ✅ 10 \n",
            "Q 70-11 A 59  ❌ 69 \n",
            "Q 79-81 A -2  ✅ -2 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 194\n",
            "36/36 [==============================] - 1s 26ms/step - loss: 0.0725 - accuracy: 0.9928 - val_loss: 0.0896 - val_accuracy: 0.9850\n",
            "Q 26-28 A -2  ✅ -2 \n",
            "Q 33-56 A -23 ✅ -23\n",
            "Q 86-86 A 0   ✅ 0  \n",
            "Q 47-97 A -50 ✅ -50\n",
            "Q 93-60 A 33  ✅ 33 \n",
            "Q 43-23 A 20  ✅ 20 \n",
            "Q 37-94 A -57 ✅ -57\n",
            "Q 37-85 A -48 ✅ -48\n",
            "Q 45-22 A 23  ✅ 23 \n",
            "Q 80-45 A 35  ✅ 35 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 195\n",
            "36/36 [==============================] - 1s 26ms/step - loss: 0.0670 - accuracy: 0.9935 - val_loss: 0.0850 - val_accuracy: 0.9875\n",
            "Q 20-42 A -22 ✅ -22\n",
            "Q 45-99 A -54 ✅ -54\n",
            "Q 14-75 A -61 ✅ -61\n",
            "Q 67-86 A -19 ✅ -19\n",
            "Q 31-47 A -16 ✅ -16\n",
            "Q 93-89 A 4   ✅ 4  \n",
            "Q 33-42 A -9  ✅ -9 \n",
            "Q 74-61 A 13  ✅ 13 \n",
            "Q 93-89 A 4   ✅ 4  \n",
            "Q 14-92 A -78 ✅ -78\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 196\n",
            "36/36 [==============================] - 1s 27ms/step - loss: 0.0656 - accuracy: 0.9941 - val_loss: 0.0812 - val_accuracy: 0.9883\n",
            "Q 47-60 A -13 ✅ -13\n",
            "Q 28-52 A -24 ✅ -24\n",
            "Q 52-36 A 16  ✅ 16 \n",
            "Q 84-76 A 8   ✅ 8  \n",
            "Q 52-79 A -27 ✅ -27\n",
            "Q 14-34 A -20 ✅ -20\n",
            "Q 88-76 A 12  ✅ 12 \n",
            "Q 70-71 A -1  ✅ -1 \n",
            "Q 53-63 A -10 ✅ -10\n",
            "Q 19-49 A -30 ✅ -30\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 197\n",
            "36/36 [==============================] - 1s 26ms/step - loss: 0.0624 - accuracy: 0.9950 - val_loss: 0.0825 - val_accuracy: 0.9883\n",
            "Q 78-72 A 6   ✅ 6  \n",
            "Q 47-84 A -37 ✅ -37\n",
            "Q 34-57 A -23 ✅ -23\n",
            "Q 93-78 A 15  ✅ 15 \n",
            "Q 33-78 A -45 ✅ -45\n",
            "Q 87-61 A 26  ✅ 26 \n",
            "Q 29-51 A -22 ✅ -22\n",
            "Q 30-26 A 4   ✅ 4  \n",
            "Q 78-72 A 6   ✅ 6  \n",
            "Q 94-60 A 34  ✅ 34 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 198\n",
            "36/36 [==============================] - 1s 26ms/step - loss: 0.0604 - accuracy: 0.9943 - val_loss: 0.0807 - val_accuracy: 0.9875\n",
            "Q 28-52 A -24 ✅ -24\n",
            "Q 35-15 A 20  ✅ 20 \n",
            "Q 26-17 A 9   ❌ 10 \n",
            "Q 41-11 A 30  ✅ 30 \n",
            "Q 58-57 A 1   ✅ 1  \n",
            "Q 54-64 A -10 ✅ -10\n",
            "Q 50-38 A 12  ✅ 12 \n",
            "Q 32-20 A 12  ✅ 12 \n",
            "Q 89-59 A 30  ❌ 20 \n",
            "Q 41-95 A -54 ✅ -54\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 199\n",
            "36/36 [==============================] - 1s 26ms/step - loss: 0.0596 - accuracy: 0.9950 - val_loss: 0.0832 - val_accuracy: 0.9875\n",
            "Q 98-94 A 4   ✅ 4  \n",
            "Q 99-37 A 62  ✅ 62 \n",
            "Q 72-35 A 37  ✅ 37 \n",
            "Q 34-26 A 8   ✅ 8  \n",
            "Q 49-69 A -20 ✅ -20\n",
            "Q 61-45 A 16  ✅ 16 \n",
            "Q 13-72 A -59 ✅ -59\n",
            "Q 37-94 A -57 ✅ -57\n",
            "Q 43-58 A -15 ✅ -15\n",
            "Q 15-63 A -48 ✅ -48\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9UbtLat6Kv4",
        "outputId": "5871366a-c61b-4673-c0c3-abba09df2b5d"
      },
      "source": [
        "_x = x_val[np.array([ind])]\n",
        "_x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[False, False, False, False,  True, False, False, False, False,\n",
              "         False, False, False, False],\n",
              "        [False, False, False, False, False, False, False, False,  True,\n",
              "         False, False, False, False],\n",
              "        [False, False,  True, False, False, False, False, False, False,\n",
              "         False, False, False, False],\n",
              "        [False, False, False, False, False, False, False, False, False,\n",
              "          True, False, False, False],\n",
              "        [False, False, False, False, False, False,  True, False, False,\n",
              "         False, False, False, False]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wa9TbDK6f2I"
      },
      "source": [
        "y = model.predict(x[:2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Z6VmE80D6hiM",
        "outputId": "fac0b999-d4aa-4c54-cfce-7f7a68b24370"
      },
      "source": [
        "ctable.decode(y[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'96 '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rcqoGRTi6ip4",
        "outputId": "8402d990-9e01-4e14-f953-f3006f0765b8"
      },
      "source": [
        "ctable.decode(x[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'97-1 '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRqDNOCJ-Ww4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}